Abstract
"© 2021 by the authors. Licensee MDPI, Basel, Switzerland.The accurate estimation of real estate value helps the development of real estate policies that can respond to the complexities and instability of the real estate market. Previously, statistical methods were used to estimate real estate value, but machine learning methods have gained popularity because their predictions are more accurate. In contrast to existing studies that use various machine learning methods to estimate the transactions or list prices of real estate properties without separating the building and land prices, this study estimates land price using a large amount of land-use information obtained from various land-and building-related datasets. The random forest and XGBoost methods were used to estimate 52,900 land prices in Seoul, South Korea, from January 2017 to December 2020. The models were also separately trained for different land uses and different time periods. Overall, the results revealed that XGBoost yields a higher prediction accuracy. Whereas the XGBoost models were more accurate on the 2020 data than on the 2017–2020 data when analyzing residential areas, the random forest models were more accurate on the 2017–2020 data than on the 2020 data. Further analysis will extend the prediction model to consider submarkets determined by price volatility and locality."
"© 2021, The Author(s).As the COVID-19 pandemic came unexpectedly, many real estate experts claimed that the property values would fall like the 2007 crash. However, this study raises the question of what attributes of an apartment are most likely to influence a price revision during the pandemic. The findings in prior studies have lacked consensus, especially regarding the time-on-the-market variable, which exhibits an omnidirectional effect. However, with the rise of Big Data, this study used a web-scraping algorithm and collected a total of 18,992 property listings in the city of Vilnius during the first wave of the COVID-19 pandemic. Afterwards, 15 different machine learning models were applied to forecast apartment revisions, and the SHAP values for interpretability were used. The findings in this study coincide with the previous literature results, affirming that real estate is quite resilient to pandemics, as the price drops were not as dramatic as first believed. Out of the 15 different models tested, extreme gradient boosting was the most accurate, although the difference was negligible. The retrieved SHAP values conclude that the time-on-the-market variable was by far the most dominant and consistent variable for price revision forecasting. Additionally, the time-on-the-market variable exhibited an inverse U-shaped behaviour."
"© 2021Property valuation contributes significantly to market economic activities, while it has been continuously questioned on its low transparency, inaccuracy and inefficiency. With Big Data applications in real estate domain growing fast, computer-aided valuation systems such as AI-enhanced automated valuation models (AVMs) have the potential to address these issues. While a plethora of research has focused on improving predictive performance of AVMs, little effort has been made on information requirements for valuation models. As the amount of data in BIM is rising exponentially, the value-relevant design information has not been widely utilized for property valuation. This paper presents a system that leverages a holistic data interpretation, improves information exchange between AEC projects and property valuation, and automates specific workflows for property valuation. A mixed research method was adopted combining the archival literature research, qualitative and quantitative data analysis. A BIM and Machine learning (ML) integration framework for automated property valuation was proposed which contains a fundamental database interpretation, an IFC-based information extraction and an automated valuation model based on genetic algorithm optimized machine learning (GA-GBR). The main findings indicated: (1) Partial information requirements can be extracted from BIM models, (2) Property valuation can be performed in a more accurate and efficient way. This research contributes to managing information exchange between AEC projects and property valuation and supporting automated property valuation. It was suggested that the infusion of BIM, ML and other emerging digital technologies might add values to property valuation and the construction industry."
"© 2021, Emerald Publishing Limited.Purpose: Real estate appraisals are becoming an increasingly important means of backing up financial operations based on the values of these kinds of assets. However, in very large databases, there is a reduction in the predictive capacity when traditional methods, such as multiple linear regression (MLR), are used. This paper aims to determine whether in these cases the application of data mining algorithms can achieve superior statistical results. First, real estate appraisal databases from five towns and cities in the State of Paraná, Brazil, were obtained from Caixa Econômica Federal bank. Design/methodology/approach: After initial validations, additional databases were generated with both real, transformed and nominal values, in clean and raw data. Each was assisted by the application of a wide range of data mining algorithms (multilayer perceptron, support vector regression, K-star, M5Rules and random forest), either isolated or combined (regression by discretization – logistic, bagging and stacking), with the use of 10-fold cross-validation in Weka software. Findings: The results showed more varied incremental statistical results with the use of algorithms than those obtained by MLR, especially when combined algorithms were used. The largest increments were obtained in databases with a large amount of data and in those where minor initial data cleaning was carried out. The paper also conducts a further analysis, including an algorithmic ranking based on the number of significant results obtained. Originality/value: The authors did not find similar studies or research studies conducted in Brazil."
"© 2021 by the authors. Licensee MDPI, Basel, Switzerland.The increase in geoheritage studies has secured recognition globally regarding the impor-tance of abiotic natural features. Prominent in geoheritage screening practices follows a multicriteria assessment framework; however, the complexity of interest in values often causes decision making to overlook geoeducation, one of the primary facets of geosystem services. Auckland volcanic field in New Zealand stretches through the whole area of metropolitan Auckland, which helps preserve volcanic cones and their cultural heritage around its central business district (CBD). They are important sites for developing tourist activities. Geoeducation is becoming a significant factor for tourists and others visiting geomorphological features, but it cannot be achieved without sound planning. This paper investigates the use of big data (FlickR), Geopreservation Inventory, and Geographic Information System for identifying geoeducation capacity of tourist attractions. Through landform classification using the Topographic Position Index and integrated with geological and the inventory data, the underpromoted important geoeducation sites can be mapped and added to the spatial database Auckland Council uses for urban planning. The use of the Geoeducation Capacity Map can help resolve conflicts between the multiple objectives that a bicultural, metropolitan city council need to tackle in the planning of upgrading open spaces while battling of growing demand for land."
"© 2021 The Author(s)Street view imagery has rapidly ascended as an important data source for geospatial data collection and urban analytics, deriving insights and supporting informed decisions. Such surge has been mainly catalysed by the proliferation of large-scale imagery platforms, advances in computer vision and machine learning, and availability of computing resources. We screened more than 600 recent papers to provide a comprehensive systematic review of the state of the art of how street-level imagery is currently used in studies pertaining to the built environment. The main findings are that: (i) street view imagery is now clearly an entrenched component of urban analytics and GIScience; (ii) most of the research relies on data from Google Street View; and (iii) it is used across myriads of domains with numerous applications – ranging from analysing vegetation and transportation to health and socio-economic studies. A notable trend is crowdsourced street view imagery, facilitated by services such as Mapillary and KartaView, in some cases furthering geographical coverage and temporal granularity, at a permissive licence."
"© 2021Green building has drawn worldwide attention due to the adverse impact of construction on the environment. This research presents a Building Information Modeling (BIM) based evaluation system for the performance assessment of green buildings. Combining BIM technology with green building analysis, the proposed approach can fully utilize the advantages of the BIM model and quickly conduct green building evaluation. A green building evaluation framework is constructed, which evaluates the green building performance from five aspects, i.e., the main building, the building envelope, the heating, ventilation and air conditioning (HVAC), the lighting and equipment, and extra points. A case study is performed to test the applicability and effectiveness of the proposed approach. Important findings are: (1) The performance of the target green building is determined as 0.87 (i.e., a fairly poor level), but it could be upgraded to 1.32 (i.e., a good level) with the consideration of extra points for the green building evaluation (2) Building renovation measures (i.e., improving the building envelop, HVAC, and lighting and equipment); could improve the performance of the green building by 31.5% on average. A synergetic impact exists among these renovation measures, where the impact of renovating all three aspects is greater than simply the sum of taking three individual measures; (3) Optimization of the green building performance could not only reduce the energy consumption but also create a more comfortable environment for the occupants, where severe conditions could be greatly reduced. The novelty of this research lies in (a) presenting a BIM-based model that is able to effectively perform the green building evaluation and optimization in a wide range and also incorporate the regional features as needed; (b) proposing a novel grading rule that makes influential factors under different standards measurable in a more intuitive manner."
"© 2021 by the authors. Licensee MDPI, Basel, Switzerland.Public transport has become one of the major transport options, especially when it comes to reducing motorized individual transport and achieving sustainability while reducing emissions, noise and so on. The use of public transport data has evolved and rapidly improved over the past decades. Indeed, the availability of data from different sources, coupled with advances in analytical and predictive approaches, has contributed to increased attention being paid to the exploitation of available data to improve public transport service. In this paper, we review the current state of the art of public transport data sources. More precisely, we summarize and analyze the potential and challenges of the main data sources. In addition, we show the complementary aspects of these data sources and how to merge them to broaden their contributions and face their challenges. This is complemented by an information management framework to enhance the use of data sources. Specifically, we seek to bridge the gap between traditional data sources and recent ones, present a unified overview of them and show how they can all leverage recent advances in data-driven methods and how they can help achieve a balance between transit service and passenger behavior."
"© 2021 by the authors. Licensee MDPI, Basel, Switzerland.As the human population increases, the landscape is altered to provide housing, food, and industry. Human activity poses a risk to the health of natural habitats that, in turn, affect biodiversity. Biodiversity is necessary for a functioning ecosystem, as species work synergistically to create a livable environment. It is, therefore, important to know how human practices and natural events threaten these habitats and the species living in them. A universal method of modeling habitat threats does not exist. This paper details the use of a literature review to formulate a new framework called Define–Investigate–Estimate–Map (DIEM). This framework is a process of defining threats, investigating an area to discover what threats are present, estimating the severity of those threats, and mapping the threats. Analysis of 62 studies was conducted to determine how different authors define and characterize threats in various contexts. The results of this analysis were then applied to a case study to evaluate the Choctawhatchee River and Bay Watershed. Results suggest that the most abundant threat in the watershed is agricultural development, and the most destructive threat is urban development. These two threats have the greatest impact on the total threat level of the watershed. Applying the DIEM framework demonstrates its helpfulness in regional analysis, watershed modeling, and land development planning."
"© 2021, The Author(s).In recent years, process mining has emerged as the leading big data technology for business process analysis. By extracting knowledge from event logs in information systems, process mining provides unprecedented transparency of business processes while being independent of the source system. However, despite its practical relevance, there is still a limited understanding of how organizations act upon the pervasive transparency created by process mining and how they leverage it to benefit from increased process awareness. Addressing this gap, this study conducts a multiple case study to explore how four organizations achieved increased process awareness by using process mining. Drawing on data from 24 semi-structured interviews and archival sources, this study reveals seven sociotechnical mechanisms based on process mining that enable organizations to create either standardized or shared awareness of sub-processes, end-to-end processes, and the firm’s process landscape. Thereby, this study contributes to research on business process management by revealing how process mining facilitates mechanisms that serve as a new, data-driven way of creating process awareness. In addition, the findings indicate that these mechanisms are influenced by the governance approach chosen to conduct process mining, i.e., a top-down or bottom-up driven implementation approach. Last, this study also points to the importance of balancing the social complications of increased process transparency and awareness. These results serve as a valuable starting point for practitioners to reflect on measures to increase organizational process awareness through process mining."
"© 2021 The Author(s)Sustainable roofs, such as those with greenery and photovoltaic panels, contribute to the roadmap for reducing the carbon footprint of cities. However, research on sustainable urban roofscapes is rather focused on their potential and it is hindered by the scarcity of data, limiting our understanding of their current content, spatial distribution, and temporal evolution. To tackle this issue, we introduce Roofpedia, a set of three contributions: (i) automatic mapping of relevant urban roof typology from satellite imagery; (ii) an open roof registry mapping the spatial distribution and area of solar and green roofs of more than one million buildings across 17 cities; and (iii) the Roofpedia Index, a derivative of the registry, to benchmark the cities by the extent of sustainable roofscape in term of solar and green roof penetration. This project, partly inspired by its street greenery counterpart ‘Treepedia’, is made possible by a multi-step pipeline that combines deep learning and geospatial techniques, demonstrating the feasibility of an automated methodology that generalises successfully across cities with an accuracy of detecting sustainable roofs of up to 100% in some cities. We offer our results as an interactive map and open dataset so that our work could aid researchers, local governments, and the public to uncover the pattern of sustainable rooftops across cities, track and monitor the current use of rooftops, complement studies on their potential, evaluate the effectiveness of existing incentives, verify the use of subsidies and fulfilment of climate pledges, estimate carbon offset capacities of cities, and ultimately support better policies and strategies to increase the adoption of instruments contributing to the sustainable development of cities."
"© 2021 Elsevier LtdEconometric modelling of choice now constitutes a major cross-over between multiple fields of research in which quantitative valuation of human preferences is of interest. The methods are pervasively used by consumer, environmental and health economists as well as transportation researchers and beyond. This work analyses the scholarly literature on econometric discrete choice modelling developed in the last fifty years. The literature is estimated to have grown beyond 14,000 research items while an excess of 1,000 new items have been published each year since 2015. This trend has essentially doubled the size of this literature within the last five years. While the largest portion of this literature is concentrated in the transportation sector, the methods are currently most trendy in health economics. This is striking given that health economists come late to adopt econometric choice methods compared to other major disciplines. Since 2014, more applications of discrete choice models have been reported in health-related studies than any other domain. Also, while the number of applications in consumer and transportation studies have been fluctuating over the past few years, applications in environmental studies are steadily on the rise at a rate comparable to that of health. Activities in the methodological cluster of this field have rather notably slowed down during the recent years although not extinct. Also, despite slowing down of choice modelling applications in transportation compared to the previous decades, such applications have not disappeared from the transportation sector. A particular area of transportation research where applications of choice modelling methods are still notably trending is electric and automated mobility. Pioneering studies, most influential studies and various streams of choice modelling research along with their time of emergence and duration of trendiness are also objectively determined using a document co-citation analysis. Further analyses are also conducted on patterns of collaboration in this field. These outcomes document the history of development of choice modelling literature at a macro scale and provide a holistic understanding of various divisions of this field along with its influential entities."
"© 2021 Elsevier GmbHUrban green spaces provide a range of services to urban residents; however, how these distinct spaces provide different services, if any, to human wellbeing has been seldom addressed. Using large volumes of social media data considering broad user groups and publicly available content, we developed a method to transform unstructured online comments into a structured assessment of nine categories of ecosystem services. An ‘ecosystem services lexicon’ was created based on 6853 words under twenty-eight subcategories of parks' services to human wellbeing using the word2vec model. The application of the ecosystem service lexicon to urban parks in Beijing revealed that all ecosystem services were perceivable to urban park users; however, the perception frequency of the ecosystem services varied across different parks. Additionally, the perceived ecosystem services were bundled together; four types of bundles were identified with varied dominant services. Technically, this study offered a novel technical procedure that can transfer unstructured free comments into a structured assessment of urban parks' perceived services to human wellbeing. Theoretically, the study revealed small-scale ecosystem service bundles from users' opinions and called for a further cross-scale understanding of ecosystem service bundles. Practically, the study findings can help inform evidence-based park policies, planning, and management."
"© 2021This study demonstrates that web-search traffic information, in particular, Google Trends data, is a credible novel source of high-quality and easy-to-access data for analyzing technology-based new ventures (TBNVs) growth trajectories. Utilizing the diverse sample of 241 US-based TBNVs, we comparatively analyze the relationship between companies’ evolution curves represented by search activity on the one hand and by valuations achieved through rounds of venture investments on another. The results suggest that TBNV's growth dynamics are positively and strongly correlated with its web search traffic across the sample. This correlation is more robust when a company is a) more successful (in terms of valuation achieved) – especially if it is a “unicorn”; b) consumer-oriented (i.e., b2c); and 3) develops products in the form of a digital platform. Further analysis based on fuzzy-set Qualitative Comparative Analysis (fsQCA) shows that for the most successful companies (“unicorns”) and consumer-oriented digital platforms (i.e., b2c digital platform companies) proposed approach may be extremely reliable, while for other high-growth TBNVs it is useful for analyzing their growth dynamics, albeit to a more limited degree. The proposed methodological approach opens a wide range of possibilities for analyzing, researching and predicting the growth of recently formed growth-oriented companies, in practice and academia."
"© 2021 by the authors.The decarbonisation of heating in the United Kingdom is likely to entail both the mass adoption of heat pumps and widespread development of district heating infrastructure. Estimation of the spatially disaggregated heat demand is needed for both electrical distribution network with electrified heating and for the development of district heating. The temporal variation of heat demand is important when considering the operation of district heating, thermal energy storage and electrical grid storage. The difference between the national and urban heat demands profiles will vary due to the type and occupancy of buildings leading to temporal variations which have not been widely surveyed. This paper develops a high-resolution spatiotemporal heat load model for Great Britain (GB: England, Scotland aWales) by identifying the appropriate datasets, archetype segmentation and characterisation for the domestic and nondomestic building stock. This is applied to a thermal model and calibrated on the local scale using gas consumption statistics. The annual GB heat demand was in close agreement with other estimates and the peak demand was 219 GWth. The urban heat demand was found to have a lower peak to trough ratio than the average national demand profile. This will have important implications for the uptake of heating technologies and design of district heating."
"© 2021 Elsevier GmbHUsers’ preferences and values in urban parks is important information for establishing social marketing strategies and therefore policymakers to consider. This study investigates the issue by analyzing social media data. User-generated data were collected from Instagram and content analysis was employed to identify physical features and values people assigned to urban parks from text descriptions of Instagram posts. Findings revealed that natural features are more frequently mentioned than non-natural elements. Aesthetic quality, feeling of happiness, and restorative experience are the most frequently mentioned expressions among the six categories of identified values. Significant association rules are established between physical features and values. Natural elements such as lawns, water features, wildlife and plants are more likely to be associated with happiness and restorative experience than aesthetic value. Artificial elements, flowers, and public art stimulate aesthetic quality. Implications for planning urban green environments are discussed. Social media platforms offer a novel entry point to uncover and monitor public interests and perceptions of specific venues such as recreational settings. Social media data provide actionable insights for promotional campaigns and inform decision-making pertaining to individuals and collective well-being."
"© The Author(s) 2020.Some of the most overlooked valuation systems in current literature are those based on expert algorithms. Yet these algorithms can form the basis of a good estimation of the value of real estate since they allow simple computational methods that use big data to be integrated with the appraiser’ own knowledge of the situation. The main usefulness of the methodology is an ongoing mortgage risk appraisal for banking institutions. The current expert algorithms based on the sales comparison approach use the arithmetic mean of the comparable prices. But this mean gives equal importance to all neighbouring dwellings instead of giving more importance to those dwellings which are more similar and are nearer to the target dwelling. Improving the classical arithmetic mean or the more robust median, this article proposes a computer-assisted expert algorithm which includes a weighted estimator able to consider the differences in characteristics compared to similar properties and their relative locations. It allows to estimate, in a simple and rapid way using objective criteria, the value of any residential property in Spain. The results show good fit for large cities in terms of the usual error margins while improving the results with regards to smaller cities. In all cases, in terms of mean absolute percentage error, the weighted estimator improves the arithmetic mean or median results."
"© The Author(s) 2020.China’s urban villages have distinct characteristics compared with the ones in western countries. Identifying urban villages provides a basis for policymakers to evaluate and improve the effectiveness of urban planning in China and other developing countries. However, perhaps due to limitations of data acquisition among others, few urban studies have successfully identified urban villages at the building level. To fill the research gap, this paper has fused multiple sources of data and utilized a three-stage model to identify urban villages in Haizhu District (Guangzhou, China). The first stage discriminates residential buildings, offices, shops, and restaurants based on various peak times of bike trajectories in different types of buildings. However, the first stage could not distinguish the regular residential buildings (in cities) and residential buildings within urban villages due to the similarity of human activities between them. It then utilized a second stage to identify residential buildings within urban villages based on the area, height, and density of buildings. In the third stage, we used correction rules to identify buildings with mixed-use and single-use buildings within urban villages. The results showed that urban villages were mainly concentrated in the western and central regions of the Haizhu District. Most of them were adjacent to shopping buildings or high-rise residential buildings. Building height and density played critical roles in the characterization of residential buildings in urban villages. Our accuracy rate was around 85% when verified against ground-truth data."
NULL
"© 2021 by the authors. Licensee MDPI, Basel, Switzerland.Agri‐food systems (AFS) have been central in the debate on sustainable development. De-spite this growing interest in AFS, comprehensive analyses of the scholarly literature are hard to find. Therefore, the present systematic review delineated the contours of this growing research strand and analyzed how it relates to sustainability. A search performed on the Web of Science in January 2020 yielded 1389 documents, and 1289 were selected and underwent bibliometric and topical analyses. The topical analysis was informed by the SAFA (Sustainability Assessment of Food and Agriculture systems) approach of FAO and structured along four dimensions viz. environment, economy, society and culture, and policy and governance. The review shows an increasing interest in AFS with an exponential increase in publications number. However, the study field is north-biased and dominated by researchers and organizations from developed countries. Moreover, the analysis suggests that while environmental aspects are sufficiently addressed, social, economic, and political ones are generally overlooked. The paper ends by providing directions for future research and listing some topics to be integrated into a comprehensive, multidisciplinary agenda addressing the multifaceted (un)sustainability of AFS. It makes the case for adopting a holistic, 4‐P (planet, people, profit, policy) approach in agri‐food system studies."
"© Noordhoff Uitgevers bv.Ethics in business is not a new topic and has been intensely discussed since the emergence of the so-called limited companies. However, privatization, technological and digital innovation, changes in moral perception, economic and financial crises and globalization stir a more recent debate on how companies should behave in our societies. This book starts from the position that ethics in business should imply an open debate on norms and values, using a sound methodology to get there. Ethics should cross borders: not only the borders of a country, but also the borders of someone’s moral imagination. Ethics should not only be about harmony but also about conflict (and how to deal with that). Ethics should be realistic and well substantiated by academic research. Ethics should be used to understand the complexity of the world, and the challenges companies struggle with on various levels. Therefore, this book is composed of three parts in which ethics is discussed at different levels. In part one we discuss ethics at the level of the individual. In part two we discuss ethics and business. In the third part, ethics is discussed in the context of a globalized world. In each chapter, we discuss the ethical complications of each topic from various - and preferably opposing - perspectives. Each perspective is methodologically and academically substantiated. Each chapter ends with an extensive literature list in which the original sources are listed for further reading. Furthermore, at the end of each chapter, a summary is written in which the most important definitions and viewpoints are highlighted. The frequent use of colorful and bold examples make this an accessible read for bachelor and master students at business schools and professionals in international business."
"© 2020, Springer-Verlag London Ltd., part of Springer Nature.This paper aims to study the actual utility of real estate pricing models based on data mining and machine learning. In order to achieve this goal, this paper introduces appropriate trend estimation methods, adjusts pricing models and processes, and realizes trend estimation that changes over time to make the resulting pricing model have advantages such as dynamics, accuracy, and flexibility over the original model. Moreover, this paper proposes a real estate pricing model based on the quadratic exponential smoothing time-varying trend estimation. In addition, this paper uses the quadratic exponential smoothing method to calculate the index trend in the random process of the house price index, and performs segmentation processing on the pricing model according to the index cycle, so as to obtain the real estate pricing method under the time-varying trend. Finally, this paper adjusts the volatility parameters and the mean recovery rate to time-varying piecewise functions, uses the quadratic variation to calculate the volatility parameters and the martingale valuation method to calculate the mean recovery rate parameters, and establishes the real estate pricing model of the time-varying O–U process. Case studies show that the model constructed in this paper has good performance and has certain practical effects."
"© 2021 by the authors. Licensee MDPI, Basel, Switzerland.The main bases for land taxation are its area or value. In many countries, especially in Eastern Europe, reforms of property taxation, including land taxation, are being carried out or planned, introducing property value as a tax base. Practice and research in this area indicate that such a change in the tax system leads to large changes in land use and reallocation. The taxation of land value requires construction of mass valuation system. Different methodological solutions can serve this purpose. However, mass land valuation requires a large amount of information on property transactions. Such data are not available in every case. The main objective of the paper is to evaluate the possibility of applying selected algorithms of machine learning and a multiple regression model in property mass valuation on small, underdeveloped markets, where a scarce number of transactions takes place or those transactions demonstrate little volatility in terms of real property attributes. A hypothesis is verified according to which machine learning methods result in more accurate appraisals than multiple regression models do, considering the size of training datasets. Three types of models were employed in the study: a multiple regression model, k nearest neighbor regression algorithm and XGBoost regression algorithm. Training sets were drawn from a larger dataset 1000 times in order to draw conclusions for averaged results. Thanks to the application of KNN and XGBoost algorithms, it was possible to obtain models much more resistant to a low number of observations, a substantial number of explanatory variables in relation to the number of observations, a low property attributes variability in the training datasets as well as collinearity of explanatory variables. This study showed that algorithms designed for large datasets can provide accurate results in the presence of a limited amount of data. This is a significant observation given that small or underdeveloped real estate markets are not uncommon."
"© 2021, Science Press. All right reserved.Nighttime light remote sensing is a unique optical remote sensing technology that can record ground object radiation information at night that cannot be obtained by daytime remote sensing. Given that artificial light in urban areas is the main source of stable nighttime light, nighttime light remote sensing images have been proven to reflect the variation in human activities at night. At the same time, they have extensive coverage, are time intensive and readily available, and have widely been a proxy for urban studies on the multi-scale or long-term analysis. The application related to the nighttime light data is growing at present. However, most reviews have focused on the preprocessing and potential application of nighttime light data, and the summary of nighttime light data in urban studies is still limited. In this study, we reviewed nighttime light-related research in three aspects: multi-scale analysis of the urban spatial structure, multi-scale estimation of urban socio-economic indicators, and research in urban public security. Three challenges, namely, the application of nighttime light data with a short time interval, the generation of longer nighttime light time series, and the quantitative validation, are also discussed to explore the potential applications in the future."
"© 2021 Survey Review Ltd.In this study, a new methodology has been developed for a sustainable mass appraisal system. A mathematical model was created with the combination of the Cobb-Douglas and the linear regression model. With the Analytic Hierarchy Process (AHP) method, real estate value criteria were grouped and weighted in a hierarchical structure. The weights obtained with AHP were integrated into the coefficients regarding the criteria weights and densities in the Cobb-Douglas hybrid model. The new hybrid model was confirmed with the features and price equivalents of 435 parcels for sale from the market. Besides, the model analysis results were compared with the Multiple Regression Analysis (MRA) modelling using market prices. While creating the methodology, Geographic Information Systems (GIS) was used to organize the geographic and regional data of the region. After developing the new hybrid model, criteria groups that developed the model and relevant sub-criteria were evaluated using Pearson's correlation analysis."
"© 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.This paper develops an artificial intelligence based automated valuation model (AI-AVM) using the boosting tree ensemble technique to predict housing prices in Singapore. We use more than 300,000 private and public housing transactions in Singapore for the period from 1995 to 2017 in the training of the AI-AVM models. The boosting model is the best predictive model that produce the most robust and accurate predictions for housing prices compared to the decision tree and multiple regression analysis (MRA) models. The boosting AI-AVM models explain 91.33% and 94.28% of the price variances, and keep the mean absolute percentage errors at 8.55% and 5.34% for the public housing market and the private housing market, respectively. When subject the AI-AVM to the out-of-sample forecasting using the 2018 housing sale samples, the prediction errors remain within a narrow range of between 5% and 9%."
"© 2021, Korean Spatial Information Society.Accurate house price estimation is of great importance not only to various real estates stakeholders such as house owners, buyers, investors, and agents but also to banking and insurance sectors among others. This estimation is a very challenging and complex task as it involves a variety of attributes. Among all attributes, location is one of the most influential attributes affecting house price. The present study has incorporated selected structural attributes and relative location through spatial attributes (geographical, infrastructural, and neighborhood) for modeling the influence of location on house prices. The hedonic model, a traditional method for estimating house price has been criticized due to nonlinearity, multicollinearity, and heteroskedasticity problems. Unlike the hedonic model, the Artificial Neural Network (ANN) permits nonlinear relationships and also tries to solve the problem of multicollinearity. The present study aims to examine the application of ANN in estimating accurate house prices and comparing the results with the Ordinary Least Squares (OLS) based hedonic model. The Gotri area located in the western part of Vadodara city, India is considered as a case study. TensorFlow (a python environment) of Google is used to implement the ANN model. In ANN model building, a three-layer network with a single hidden layer and RELU (REctified Linear Unit) activation function is adopted. The estimation performance has been evaluated by employing Root Mean Squared Error and Mean Absolute Percentage Error. According to results, ANN was found better when compared to OLS in terms of both the performance measures. This paper suggests that the ANN estimator could be a complement to the OLS based linear regression method."
"© 2021 Wiley Periodicals LLC.The need for accurate and unbiased assessment of residential real property has always been important not only to financial institutions lending on or holding such assets but also to municipalities that rely on property taxes as their critical source of revenue. The common methodology for predicting residential property sale price is based on traditional multiple regression in spite of known issues. Machine learning methods have been proposed as an alternative approach but the results are far from satisfactory. A review of existing studies and relevant issues can help researchers better assess the pros and cons of the approaches in this important stream of research and move the field forward. This article provides such a review. In our review, we have noticed that common to both the regression-based methods and machine learning methods are the use of batch-mode learning. Thus in addition to providing a review of recent research on batch-based residential property prediction models, this article also explores a new approach to constructing residential property price prediction models by treating past sale records as an evolving data stream. The results of our study show that the data stream approach outperforms the traditional regression method and demonstrate the potential of data stream methods in improving prediction models for residential property prices. This article is categorized under: Application Areas > Business and Industry Technologies > Machine Learning Technologies > Prediction."
"© 2021, The Author(s).Assuming that it is not possible to detach a dwelling from its location, this article highlights the relevance of space in the context of housing market analysis and the challenge of capturing the key elements of spatial structure in an automated valuation model: location attributes, heterogeneity, dependence and scale. Thus, the aim is to present a spatial automated valuation model (sAVM) prototype, which uses spatial econometric models to determine the value of a residential property, based on identification of eight housing characteristics (seven are physical attributes of a dwelling, and one is its location; once this spatial data is known, dozens of new variables are automatically associated with the model, producing new and valuable information to estimate the price of a housing unit). This prototype was developed in a successful cooperation between an academic institution (University of Aveiro) and a business company (PrimeYield SA), resulting the Prime AVM & Analytics product/service. This collaboration has provided an opportunity to materialize some of fundamental knowledge and research produced in the field of spatial econometric models over the last 15 years into decision support tools."
"© 2021 Informa UK Limited, trading as Taylor & Francis Group.It is well known most often that values of properties tend to hike at the effluxion of time. This has necessitated the adoption of predictive models in interpreting outcomes in the property market in the future. Earlier studies have been oblivious of such models' outcomes as it affects any focal group, particularly the vulnerable. This present study focuses on the low-income earners found in the slum. The Ijora community in Lagos was the highlight of this study, particularly Ijora Badia and Ijora Oloye, regarded as slums according to the UNDP report. The entire fifty-two (52) local agents in the Ijora community were surveyed in cross-sectional survey research that entailed the questionnaire's issuance. The nexus of data collection, pre-processing, data analysis, algorithm application, and model evaluation resulted in retrieving rental values within the years 2010 and 2019 on two predominant residential property types of self-contain and one-bedroom flats found within the community. Three selected algorithms, Artificial Neural Network (ANN), Support Vector Machine, and Logistic Regression, were essentially used as classifiers but trained to predict the continuous values. These algorithms were implemented through the use of Python's SciKit-learn Library and RapidMiner. The findings revealed that though all three models gave accurate predictions, Logistic Regression was the highest with low error values. It was recommended that Logistic Regression be applied but with much data set of property values of low-income earners over much more period. This study will contribute to the Sustainable development goals(SDG) 11(Sustainable cities and communities) of the United Nations to benefit developing countries, especially in sub-Saharan Africa."
"© 2021, The Author(s), under exclusive licence to Springer Nature B.V.In contrast to the brilliant success of deep learning approach in dealing with unstructured data such as image and natural language, it has not shown noticeable achievements in handling structured data, that is, tabular format data. Categorical data types form a considerable portion of structured data, and a neural network, the most universal implementation algorithm for deep learning, is inefficient in processing these data types. This is a reason for the poor performance of the neural network applied to the structured data. In this study, a neural network is used to estimate land prices in the Gyunggi province, South Korea. To enhance the performance of the network when most input variables are categorical, the architecture of the neural network is specified using the entity embedding layers, a technique to reveal the continuity inherent in categorical data. This study demonstrates that information in the categorical data can be efficiently extracted by the entity embedding technique. The network architecture proposed in this study can be applied in valuation practices where categorical data are abundant. In addition, the interpretation of the resultant embedding layers can enhance the explainability of the deep learning approach, promoting its rapid adoption in the real estate industry."
"© 2021, The Author(s).Separating urban land and structure values is important for national accounts and for analysis of real estate risk over time. A large part of the literature on urban land valuation uses the land residual method, which relies on the assumption that structures are easily replaced. But urban land value depends on accessibility to nearby land uses, implying that infrastructure and the slowly changing built environment are the most important components of land value. Investments in structures are only slowly reversible, implying that land and structure function as a bundled good whereas land residual theory severs the connection between land value and structure value over time. We develop a simple theoretical model that includes option value and compare to a nested land residual model before and after a shock to values. Cross-sectionally our model shows that land residual theory overestimates structure value. Over time almost all of any change in property value is allocated to land residuals. Data from Maricopa county, AZ, 2012–2018 strongly support option value models when nested within a general model that also includes land residuals. FHFA estimates use entirely different cost estimation methods: our analysis of FHA data suggest that our conclusions generalize to the U.S. as a whole, and that high and rising land value ratios over 50 years (the “hockey stick” pattern found in the literature) are likely an artifact of the residual model."
"© 2021, Emerald Publishing Limited.Purpose: At the end of a building’s lifecycle, there are several limitations to the decision-making process (DMP). There is a lack of data available from the building’s history, the difficulty in assessing the condition of a building and the variety of stakeholders’ needs that have to be satisfied. The purpose of this paper is to answer the question: how would end-of-life (EOL) DMP change when buildings will have been digitally built? The answer will be illustrated through a conceptual framework. Design/methodology/approach: A qualitative analysis of the existing literature has been performed to identify the elements within building information modelling (BIM) and advanced digital technologies that could be of support to the DMP. The findings have been collected and summarised in a conceptual framework that has been validated and enhanced through online interviews with industry experts. Findings: The enhanced framework has identified that BIM technology would bring the benefit of providing the initial digital data source, from which machine learning and data analytics would then extract the relevant data needed to measure accurately the criteria during the analysis of the EOL options put on the table. Originality/value: The findings of this research could contribute to developing the software modules making the bridge between BIM and machine learning technologies, to implement them in the EOL DMP."
"© 2021, Emerald Publishing Limited.Purpose: This study is aimed to identify the attributes for a valuation approach of flood risk exposure, in particular for residential property. With frequent flood events in Malaysia, there is a need for valuation methods to evolve and represent the increased risk of natural disasters. Design/methodology/approach: This study employed the Delphi method which is a systematic and interactive research technique in obtaining variables for a valuation approach for residential property exposed to flood risk. Findings: Results from the Delphi method revealed four categories of attributes, namely environmental, locational, structural and economical. Originality/value: The findings from this research will transform the valuation approach in Malaysia to identify the value of residential property exposed to flood risk. The determination of variables will represent the current risk in valuations, especially for residential property in flood-prone areas."
"© 2021, European Regional Science Association. All rights reserved.Bratislava, the capital city of Slovakia, is currently experiencing a period of intensive suburbanisation, which in turn creates demand pressures and increases the price of urban land located in its hinterlandThis paper investigates several locational factors, which likely significantly influence the demand for land plots and modulate 'price-maker' conditionsBased on the population sample of 102 units, the results indicate that builtin infrastructure facilities on land under analysis, advanced transport connectivity in municipalities, and various amenities in the municipality cadastre tend to elevate land prices significantlyMoreover, the factor of distance from the city of Bratislava plays a major role in household location, which was identified by the apparent decreasing rent gradient pattern."
"© 2021 by the authors. Licensee MDPI, Basel, Switzerland.The residential real estate market is very important because most people’s wealth is in this sector, and it is an indicator of the economy. Real estate market data in general and market transaction data, in particular, are inherently spatiotemporal as each transaction has a location and time. Therefore, exploratory spatiotemporal methods can extract unique locational and temporal insight from property transaction data, but this type of data are usually unavailable or not sufficiently geocoded to implement spatiotemporal methods. In this article, exploratory spatiotemporal methods, including a space-time cube, were used to analyze the residential real estate market at small area scale in the Dublin Metropolitan Area over the last decade. The spatial patterns show that some neighborhoods are experiencing change, including gentrification and recent development. The extracted spatiotemporal patterns from the data show different urban areas have had varying responses during national and global crises such as the economic crisis in 2008–2011, the Brexit decision in 2016, and the COVID-19 pandemic. The study also suggests that Dublin is experiencing intraurban displacement of residential property transactions to the west of Dublin city, and we are predicting increasing spatial inequality and segregation in the future. The findings of this innovative and exploratory data-driven approach are supported by other work in the field regarding Dublin and other international cities. The article shows that the space-time cube can be used as complementary evidence for different fields of urban studies, urban planning, urban economics, real estate valuations, intraurban analytics, and monitoring sociospatial changes at small areas, and to understand residential property transactions in cities. Moreover, the exploratory spatiotemporal analyses of data have a high potential to highlight spatial structures of the city and relevant underlying processes. The value and necessity of open access to geocoded spatiotemporal property transaction data in social research are also highlighted."
"© 2021, Emerald Publishing Limited.Purpose: Dynamic planning and scheduling forms a widely adopted smart strategy for solving real-world problems in diverse business systems. This paper uses deductive content analysis to explore secondary data from previous studies in dynamic planning and scheduling to draw conclusions on its current status, forward action and research needs in construction management. Design/methodology/approach: We searched academic databases using planning and scheduling keywords without a periodic setting. This research collected secondary data from the database to draw an objective comparison of categories and conclusions about how the data relates to planning and scheduling to avoid the subjective responses from questionnaires and interviews. Then, applying inclusion and exclusion criteria, we selected one hundred and four articles. Finally, the study used a seven-step deductive content analysis to develop the categorisation matrix and sub-themes for describing the dynamic planning and scheduling categories. We used deductive analysis because of the secondary data and categories comparison. Using the event types represented in a quadrant mapping, we delve into where, when, application and benefits of the classes. Findings: The content analysis showed that all the accounts and descriptions of dynamic planning and scheduling are identifiable in an extensive research database. The content analysis reveals the need for multi-hybrid (4D BIM-Agent based-discrete event-discrete rate-system dynamics) simulation modelling and optimisation method for proffering solutions to scheduling and planning problems, its current status, tools and obstacles. Originality/value: This research reveals the deductive content analysis talent in construction research. It also draws direction, focuses and raises a question on dynamic planning and scheduling research concerning the five-integrated model, an opportunity for their integration, models combined attributes and insight into its solution viability in construction."
"© 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.Automated Valuation Models (AVMs) based on Machine Learning (ML) algorithms are widely used for predicting house prices. While there is consensus in the literature that cross-validation (CV) should be used for model selection in this context, the interdisciplinary nature of the subject has made it hard to reach consensus over which metrics to use at each stage of the CV exercise. We collect 48 metrics (from the AVM literature and elsewhere) and classify them into seven groups according to their structure. Each of these groups focuses on a particular aspect of the error distribution. Depending on the type of data and the purpose of the AVM, the needs of users may be met by some classes, but not by others. In addition, we show in an empirical application how the choice of metric can influence the choice of model, by applying each metric to evaluate five commonly used AVM models. Finally–since it is not always practicable to produce 48 different performance metrics–we provide a short list of 7 metrics that are well suited to evaluate AVMs. These metrics satisfy a symmetry condition that we find is important for AVM performance, and can provide a good overall model performance ranking."
"© 2021, The Author(s).One of the largest problems in the real estate market analysis, which includes valuation, is determining the significance of individual property attributes that may affect value or attractiveness perception. The study attempts to assess the significance of selected attributes of real estate based on the detection and analysis of the emotions of potential investors. Human facial expression is a carrier of information that can be recorded and interpreted effectively via the use of artificial intelligence methods, machine learning and computer vision. The development of a reliable algorithm requires, in this case, the identification and investigation of factors that may affect the final solution of the problem, from behavioural aspects through technological possibilities. In the presented experiment, an approach that correlates the emotional states of buyers with the visualization of selected attributes of properties is utilized. The objective of this study is to develop an original method for assessing the significance of property attributes based on emotion recognition technology as an alternative to the commonly used methods in the real estate analysis and valuation, which are usually based on surveys. The empirical analysis enabled determination of the mainstream property attributes significance from evoked emotions intensity within the group of property clients (represented by 156 respondents). The significance ranking determined on the basis of the unconscious expressed facial emotions was verified and compared to the answers given in a form of questionnaire. The results have shown that the conscious declaration of the attribute ranking differs from the emotion detection conclusions in several cases."
"© 2021 Architectural Institute of Korea.As the real estates occupy major portion of domestic households assets, relevant issue has been dealt seriously by the Korean government. However, apartment prices in downtown Seoul, the capital city, have soared despite various policies. Forecasting the real estate market trend has become an important research topic in order to provide information for establishing policies. In the prediction of the real estate market in the previous studies, two research directions were classified as follows: quantitative economic models and machine learning models. Regarding this trend, there was a need for comparative research on machine learning models, emerging methods, that are used to compare and predict various real estate indices. In this study, the machine learning model RF(Random Forest), XGBoost(eXtreme Gradient Boosting), and LSTM (Long Short Term Memory) are used to select suitable machine learning models for selected real estate index and conduct a comparative study to validate predictive power of machine learning models. Apartment sales index, land price index, charter price index, and real estate psychological index using univariate variables are predicted. In addition, RF, XGBoost and LSTM models all tended to be generally marginal with RMSE values of 0.0268, 0.0296, and 0.0259 in charter(Jeonse), Korean traditional pre-deposit rental system, price index data with linear but small variants. This shows that the prediction of the real estate index is deviated from the prediction accuracy of machine learning models depending on the periodic characteristics and data characteristics of the real estate index."
"© 2021 The Ohio State UniversityDespite several attempts to compare and examine the predictive accuracy of real estate sales and rent prices between the regression-based and neural-network (NN)-based approaches, the results are largely mixed. Prior study limitations include a small sample size and a disregard for spatial dependence, which is an essential characteristic of real estate properties. Hence, this study aims to add new empirical evidence to the literature on comparing regression-based with NN-based rent price prediction models through sophistications by (1) examining different and relatively large-scale sample sizes (n = 104, 105, 106), and (2) considering the spatial dependence of either the application of nearest neighbor Gaussian processes (NNGP) or the latitude-longitude coordinate function (in the case of a deep neural network [DNN]). A case study of apartment rent prices in Japan shows that, given an increase in sample size, the out-of-sample predictive accuracies of the DNN approaches and that of NNGP are nearly equal in the order of n = 106. However, the DNN may have higher predictive accuracy than the NNGP for both higher- and lower-end properties whose rent prices deviate from the median."
"© Springer Nature Switzerland AG 2021.In this paper a hedonic price function built through a semiparametric additive model was applied for the real estate market analysis of the central area of Reggio Calabria. Based on Penalized Spline functions, the semiparametric model aimed to detect and identified the existence of a market premium arising from the choice of sustainable interventions, in terms of higher real estate values. The objective of the research is to demonstrate how choosing sustainability, i.e. policies oriented to Green Buildings practices, besides mitigating energy consumption respecting the historical instance of buildings, are also able to generate economic impacts in terms of increased market value of the properties."
"© Springer Nature Switzerland AG 2021.In this paper a geoadditive model based on penalized spline functions has been applied in order to obtain a spatial distribution of real estate unitary values for a central area of the city of Reggio Calabria (Italy). This for the individuation of progressive real estate sub-samples characterized by a market premium for the presence of green buildings. Geoadditive models allow to predict, quantify and locate in real time where and how real estate values vary in urban context, with possibility to correlate these variations with any phenomenon or economic effect. The combined use of penalized splines with techniques of spatial statistics allows to obtain spatial maps with high reliability on which to base any decisions related to urban investments."
"© 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.In 2017 the European AVM Alliance emphasized the importance of Automated Valuation Methods, to be used to assess market values and/or to monitor the evolution of property prices. This last aspect has acquired a particular cogency for market operators (sellers, buyers, investors, etc.) over time, in order, on the one hand, to make reliable valuations and, on the other hand, to effectively and quickly check the trend of the values. The present research aims at analyzing the functional relationships between the unit selling prices and the explanatory variables that contribute to their formation. The study has been carried out on a sample of two-hundred and ten residential properties, sold in the period 2016–2017 and located in the city of Tarragona (Spain). The main factors considered by sellers and buyers in the preliminary negotiation phase have been collected. The implementation of a data-driven technique has allowed to identify a statistically reliable model which, in addition to highlight the most influencing factors, has shown the interdependences between the variables considered and the unit selling prices."
"© 2020 Elsevier LtdRapid changes that are taking place in the urban environment have significant impact on urban growth. Most cities and urban regions all over the world compete to increase resident and visitor satisfaction. The growing requirements and rapidity of introducing new technologies to all aspects of residents’ lives force cities and urban regions to implement “smart cities” concepts in their activities. Real estate is one of the principal anthropogenic components of urban environment thus become a subject of thorough multidisciplinary analysis in the field of data requiring spatial information systems. Recent advances in information technology, combined with the increased availability of high-resolution imagery from Earth observation, create an opportunity to use new sources of data that enable to identify, monitor, and solved many of urban environmental problem. The aim of the paper is to elaborate precise, complete and detailed property information with the use of remote sensing observations in a suitable numerical algorithm. The authors concentrate on providing one of the most important, and probably the most lacking, feature describing properties – building usable floor area (BUFA). The solution is elaborated in the form of an automatic algorithm based on machine learning and computer vision technology related to LiDAR (big data), close range images with respect to spatial information systems requirements. The obtained results related to BUFA estimation in comparison to the state-of-the-art results are satisfactory and may increase the reliability of decision-making in investment, fiscal, registration and planning aspects."
"© 2020 Survey Review Ltd.The main purpose of this study is to propose an interoperable land valuation data model for residential properties as an extension of the national geographic data infrastructure (GDI) and to make mass valuation process applicable with the use of machine learning approach. As an example, random forest (RF) ensemble algorithm was implemented in Pendik district of Istanbul to evaluate the prediction performance by using thematic datasets compatible with the data model. This study provides a methodology for various urban applications and robustness of the algorithm increases the prediction of the real estate values with the use of qualified datasets."
"© 2020 by the authors. Licensee MDPI, Basel, Switzerland.In this work, technological feasibility of autonomous corrosion assessment of reinforced concrete structures is studied. Corrosion of reinforcement bars (rebar), induced by carbonation or chloride penetration, is one of the leading causes for deterioration of concrete structures throughout the globe. Continuous nondestructive in-service monitoring of carbonation through pH and chloride ion (Cl−) concentration in concrete is indispensable for early detection of corrosion and making appropriate decisions, which ultimately make the lifecycle management of RC structures optimal from resources and safety perspectives. Critical state-of-the-art review of pH and Cl− sensors revealed that the majority of the sensors have high sensitivity, reliability, and stability in concrete environment, though the experiments were carried out for relatively short periods. Among the reviewed works, only three attempted to monitor Cl− wirelessly, albeit over a very short range. As part of the feasibility study, this work recommends the use of internet of things (IoT) and machine learning for autonomous corrosion condition assessment of RC structures."
"© 2020 Elsevier LtdCurrently we are facing the pandemic situation that occur all over the world. Regardless the country or even the region, the negative consequences that are expected could be very big and the level of crisis is not predictable. This situation is the challenge for the real estate market as well. Due to this fact, the authors believe that there is the time when deep transformation of approaches, procedures and awareness related to valuation domain becomes. Today, due to the fact of the global COVID-19 and pandemic restrictions is the best time to implement the automated models and advanced technological solutions to the valuation world. The authors proposed the hybrid approach that is the way to reconcile the participants on the property market. Hybrid approach is understanding as the synergy in combining aspects of new (automated solutions) and traditional components that are developed in the agile mode system creation. The proposed solutions can be treated as a cure for some symptoms of the real estate market infection but also as a vaccine, which should to a large extent prevent restrictions and nuisance in real estate valuation in case of repeated infection."
"© 2020 IEEE.At present, frequent natural and human-involved disasters and urgent events pose serious threats to human society and call for the smart response system for city emergencies to improve its disaster preparedness and response. In this paper, we first investigate the challenges of the emergency response system, including the inefficiency of prediction before emergencies, uncoordinated preparedness for disasters, and lacking communication and collaboration across different departments as well as unpreparedness of secondary challenges in healthcare, environmental protection, and humanity. We then evaluate, from the UV perspective, the current status of the smart response system for city emergencies based on the framework of a closed feedback control loop: data acquisition, communication, decision-making, and action. We propose that effective smart emergency response should consider the interaction between smart response system for city emergency and other seven smart city subsystems: smart home, smart medicine and healthcare, intelligent transportation, urban planning and crowd management, smart energy management, smart city infrastructure, smart environmental protection system, and smart humanity. It should also study how smart emergency response would be affected by four major impacting factors of smart cities: information flow, material cycle, lifestyle, and community. This systematic study enables us to improve preparedness, coordination adaptiveness, safety, robustness resilience of the current smart emergency response system and propose a UV-oriented, integrated, resilient, inclusive, and sustainable development framework design to address current imminent challenges and improve the response-ability through 1) hierarchical emergency response procedures for individuals, communities, and cities before, during, and after emergencies 2) hybrid, integrative, needed-based data acquisition 3) effective communication channel construction and information sharing 4) adaptive decision-making based on hierarchical knowledge level 5) human-centered and capacity-focused action."
"© 2020 by the authors. Licensee MDPI, Basel, Switzerland.As 3D cadastres offer advantages in several areas by providing information with greater accuracy and a high level of detail, a diagnosis of the cadastral situation is required prior to the implementation of a 3D cadastral model. Therefore, this study focuses on diagnosing the urban cadastral situation in Ecuador based on an analysis of eight cantonal decentralized autonomous governments that were selected primarily for the availability of their cadastral information. The twelve characteristics included in the analysis supported the definition of a cadastral development scale based on the fulfillment of each characteristic. The official cadastral databases, meetings, and interviews with personnel related to the cadastres were used in the analysis to gain in-depth knowledge of the situation in each canton. The findings demonstrated that most cantons had similar characteristics and are at an intermediate level of cadastral development. Therefore, there is the need for cantons to have standardized cadastral information in accordance with national and international regulations. Thus, in this research, we developed an initial Ecuadorian land administration domain model country profile to initiate the transition towards 3D cadastre."
"© 2020 by the authors.The article discusses cadastral land valuation in Russian resort towns, a procedure flawed by the fact that it does not take into account territorial prestige. Researchers in Russia and other countries state that it is essential to redistribute the land tax burden as the current situation creates tax injustice, which is reflected in the undervaluation of prestigious areas and the overvaluation of non-prestigious ones in resort towns. Competition for the most prestigious areas in such towns mainly stems from the opportunity for landowners to earn higher rental incomes during the high season. In view of this, the study aims to provide a method for cadastral land valuation in resort towns based on zoning by prestige. The application of the proposed method is demonstrated using the town of Anapa (a Russian resort town by the Black Sea) as a case study. The method is based on several research and analysis methods, including the following: the analytical method, which is used for a preliminary analysis of urban areas to identify the most attractive parts of resort towns; a modification of Saaty's methodology combined with Pareto analysis, which is used to identify criteria for assessing how prestigious and important a part of the town is; cluster analysis, which is used for ranking areas in resort towns; correlation and regression analysis, which is used for land valuation modelling. The article describes the key criteria for ranking areas in resort towns by prestige, gives a definition of prestige applied to resort town districts, and proposes an equation for calculating the integral indicator of prestige and a method for assessing prestige. The validity of the prestige map that was created for the town of Anapa was proved by analyzing the average market prices for land plots located within the identified zones. The cadastral land valuation models describing land plots in Anapa that are intended for private housing construction can be correctly interpreted and are of acceptable quality."
"© 2020 Informa UK Limited, trading as Taylor & Francis Group.Point estimates from Automated Valuation Models (AVMs) represent the most likely value from a distribution of possible values. The uncertainty in the point estimate–the width of the range of possible values at a given level of confidence–is a critical piece of the AVM output, especially in collateral and transactional situations. Estimating AVM uncertainty, however, remains highly unstandardised in both terminology and methods. In this paper, we present and compare two of the most common approaches to estimating AVM uncertainty–model-based and error-based prediction intervals. We also present a uniform language and framework for evaluating the calibration and efficiency of uncertainty estimates. Based on empirical tests on a large, longitudinal dataset of home sales, we show that model-based approaches outperform error-based ones in all but cases with very highest confidence level requirements. The differences between the two methods are conditioned on model class, geographic data partitions and data filtering conditions."
"© 2020 Elsevier B.V.The property value assessment in the real estate market still remains as a challenges due to incomplete and insufficient information, as well as the lack of efficient algorithms. House attributes, such as size and number of bedrooms, are currently being employed to perform the estimation by professional appraisers and researchers. Numerous algorithms have been proposed; however, a better assessment performance is still expected by the market. Nowadays, there are more available relevant data from various sources in urban areas, which have a potential impact on the house value. In this paper, we propose to fuse urban data, i.e., metadata and imagery data, with house attributes to unveil the market value of the property in Philadelphia. Specifically, two deep neural networks, i.e., metadata fusion network and image appraiser, are proposed to extract the representations, i.e., expected levels, from metadata and street-view images, respectively. A boosted regression tree (BRT) is adapted to estimate the market values of houses with the fused metadata and expected levels. The experimental results with the data collected from the city of Philadelphia demonstrate the effectiveness of the proposed model. The research presented in this paper also provides the real estate industry a new reference to the property value assessment with the data fusion methodology."
"© 2020 by the authors.Multi-Criteria Decision-Analysis (MCDA) methods are successfully applied in different fields and disciplines. However, in many studies, the problem of selecting the proper methods and parameters for the decision problems is raised. The paper undertakes an attempt to benchmark selected Multi-Criteria Decision Analysis (MCDA) methods. To achieve that, a set of feasible MCDA methods was identified. Based on reference literature guidelines, a simulation experiment was planned. The formal foundations of the authors' approach provide a reference set of MCDA methods ( Technique for Order Preference by Similarity to Ideal Solution (TOPSIS), VlseKriterijumska Optimizacija I Kompromisno Resenje (VIKOR), Complex Proportional Assessment (COPRAS), and PROMETHEE II: Preference Ranking Organization Method for Enrichment of Evaluations) along with their similarity coefficients (Spearman correlation coefficients and WS coefficient). This allowed the generation of a set of models differentiated by the number of attributes and decision variants, as well as similarity research for the obtained rankings sets. As the authors aim to build a complex benchmarking model, additional dimensions were taken into account during the simulation experiments. The aspects of the performed analysis and benchmarking methods include various weighing methods (results obtained using entropy and standard deviation methods) and varied techniques of normalization of MCDA model input data. Comparative analyses showed the detailed influence of values of particular parameters on the final form and a similarity of the final rankings obtained by different MCDA methods."
"© 2020 by the authors.In the construction industry, it is the material production phase and the use phase of buildings’ life cycles that represent the greatest environmental burden. The presented research focused on wood constructions during their use phase. The primary objective of the research was to determine the amount of CO2 produced during the operation of specific wood constructions in connection with the energy demand for their heating. A correlation analysis of selected parameters revealed a statistically significant correlation between heating medium type and energy demand for heating (p = −0.5773) and between heating medium type and amount of CO2 produced (p = 0.4796). A more detailed analysis showed that, in terms of the average energy demand for heating, the column constructions were the most efficient among the compared construction systems, regardless of the energy standard. Similar findings were obtained for annual CO2 production in connection with the average energy demand for heating. The only difference was that the panel and log constructions exhibited almost identical parameters, which came as a surprise to some extent. The column constructions turned out to be the most efficient again, regardless of their energy standard. The analysis that focused on the heating medium type revealed statistically significant differences among the heating medium types in energy demand for heating (p < 0.0001). The constructions that used electricity for heating were the most energy-efficient. When the individual characteristics of the different heating media in relation to CO2 production were taken into account, the constructions that were heated using biomass were the least polluting. The constructions heated using electricity and gas showed a significantly greater deviation."
"© 2020 by the authors.The principle behind sustainable city movements is represented by the idea of ""good living"", which is the possibility of having solutions and services that allow citizens to live in an easy, simple, and enjoyable way. Policies for urban quality play a central role in the slow cities manifesto, often suggesting the use of Information and Communication Technologies (ITC) in the development of interactive services for citizens. Among these, an interesting possibility is to offer citizens digital real estate consultancy services through the implementation of automated evaluation methods. An automated appraisal action-which is already complex in itself owing to the need to collect data in a consistent, standardized, but also differentiated way so as to require the adoption of real estate due diligence-collides on the operational level with the concrete difficulty of acquiring necessary data, much more so since the reference market is dark, atypical, and viscous. These operational difficulties are deepened by the epistemological nature of the appraisal discipline itself, which bases its methodology on the forecast postulate, recalling the need to objectify as much as possible the evaluation from the perspective of an intersubjective sharing argument. These circumstances have led, on the one hand, to the definition of internationally accepted uniform evaluation rules (IVS, 2017) and, on the other, to the testing of automated valuation methods aimed at returning computer-based appraisals (AVM). Starting from the awareness that real estate valuation refers essentially to information and georeferences, this paper aims to demonstrate how real estate appraisal analysis can be further improved through information technology (IT), directing real estate valuation towards objectivity in compliance with international valuation standards. Particularly, the paper intends to show the potential of combining geographic information systems (GISs) and building information models (BIMs) in automated valuation methods through the depreciated reproduction cost. The paper also proposes a BIM-GIS semi-automatic prototype based on the depreciated reconstruction cost through an experimentation in Rende (Italy)."
"© 2020, Editorial Board of Journal of Systems Engineering Society of China. All right reserved.With the unprecedented development of big data and artificial intelligence, data intelligence has emerged as a focal point in both academia and industry. It features in a set of predictive data analytics methods gathered in a big-data driven and applications oriented manner, including data mining, machine learning, deep learning, etc. It aims to extract valuable patterns from big data generated inside and outside targeted application scenarios so as to enhance real-life management and decision-making levels. This paper thus focuses on introducing the recent advances in data intelligence, which is formulated as a cyclic system including three naturally integrated and mutually functional dimensions: Data, algorithms, and scenarios. We discuss the hot topics, growing trends, as well as research challenges in data intelligence, with our own comments and opinions aiming to provide guidance for entering the area of data intelligence and arouse peer discussions on this exciting field."
"© 2020 by the authors.The financial transmission of the USA's housing price bubble has highlighted the inadequacy of the valuation methods adopted by the credit institutions, due to their static nature and inability to understand complex socio-economic dynamics and their related effects on the real estate market. The present research deals with the current issue of using Automated Valuation Methods for expeditious assessments in order to monitor and forecast market evolutions in the short and medium term. The paper aims to propose an evaluative model for the corporate market segment, in order to support the investors', the credit institutions' and the public entities' decision processes. The application of the proposed model to the corporate real estate segment market of the cities of Rome and Milan (Italy) outlines the potentialities of this approach in property big data management. The elaboration of input and output data in the GIS (Geographic Information System) environment allowed the development of an intuitive platform for the immediate representation of the results and their easy interpretation, even to non-expert users."
"© 2020 by the authors.In this paper, we propose a novel procedure designed to apply comparable sales method to the automated price estimation of real estates, in particular, that of apartments. Apartments are the most popular residential housing type in Korea. The price of a single apartment is influenced by many factors, making it hard to estimate accurately. Moreover, as an apartment is purchased for living, with a sizable amount of money, it is mostly traded infrequently. Thus, its past transaction price may not be particularly helpful to the estimation after a certain period of time. For these reasons, the up-to-date price of an apartment is commonly estimated by certified appraisers, who typically rely on comparable sales method (CSM). CSM requires comparable properties to be identified and used as references in estimating the current price of the property in question. In this research, we develop a procedure to systematically apply this procedure to the automated estimation of apartment prices and assess its applicability using nine years' real transaction data from the capital city and the most-populated province in South Korea and multiple scenarios designed to reflect the conditions of low and high fluctuations of housing prices. The results from extensive evaluations show that the proposed approach is superior to the traditional approach of relying on real estate professionals and also to the baseline machine learning approach."
"© 2020, Emerald Publishing Limited.Purpose: This study presents a structured investigation of the most important causes for delay in commercial real estate transactions. It assesses the potential of digital technologies such as “Blockchain”, “Property Passports” or “Automated Valuation Models” to make transactions faster and cheaper. Design/methodology/approach: The authors conduct a focus group interview to identify the individual steps and the parties involved in real estate transactions. Subsequently, the authors discuss the prospects of digital technologies based on semi-structured interviews with real estate professionals and PropTech executives, and a comprehensive screening of technological solutions offered by PropTech firms. Findings: The lack of an up-to-date, single pool of standardised property information turns out to be the most critical cause for delay in real estate transactions. However, the most promising technologies to mitigate this problem, in particular digital property passports summarising all relevant building information, face substantial barriers to adoption. The real estate industry has so far not been willing to more openly share data, which is a pre-requiste for the successful introduction of property passports. In addition, the principle of caveat emptor makes a lengthy due diligence process essential for buyers. Practical implications: The authors conclude that industry-wide collaborations are necessary to help major efficiency gaining technologies to break through. Insurance products should accompany property data log books to guarantee the quality of data provided. Originality/value: This study considers the potential impact of technologies in the wider context of the complete real estate transaction process. It identifies the major phases of that process and the associated bottlenecks. The authors gather evidence both from industry experts and PropTech executives and contrast their views regarding the potential of digital technologies to remove those bottlenecks."
"© 2020 Valentas Gruaauskas et al..Real estate valuation uses 3 main approaches: Income, cost and comparative. When applying the comparative method, correction coefficients based on similar real estate transactions are determined. In practice, the coefficients and similar real estate objects are usually determined by using qualitative approach based on the valuators' experience. The paper provides an analytical method for the determination of correction coefficient, which limits subjectivity when using the comparative method for valuation. The provided analytical approach also integrates macroeconomic indicators in the calculation process. It also addresses issues when available historical real estate transaction data is limited. A machine learning approach was applied to determine the average price of real estate in the region, with the possibility of using this information to obtain correction coefficients where historical data was unavailable. Alternative research usually focuses on final price estimation of the selected real estate object; however, the valuation standard of Tegova released in 2018 does not allow for applying analytically based approaches for individual real estate object evaluation; these approaches can be used only as a supportive tool for valuators."
"© 2020 by the authors.The traditional linear regression model of mass appraisal is increasingly unable to satisfy the standard of mass appraisal with large data volumes, complex housing characteristics and high accuracy requirements. Therefore, it is essential to utilize the inherent spatial-temporal characteristics of properties to build a more effective and accurate model. In this research, we take Beijing's core area, a typical urban center, as the study area of modeling for the first time. Thousands of real transaction data sets with a time span of 2014, 2016 and 2018 are conducted at the community level (community annual average price). Three different models, including multiple regression analysis (MRA) with ordinary least squares (OLS), geographically weighted regression (GWR) and geographically and temporally weighted regression (GTWR), are adopted for comparative analysis. The result indicates that the GTWR model, with an adjusted R2 of 0.8192, performs better in the mass appraisal modeling of real estate. The comparison of different models provides a useful benchmark for policy makers regarding the mass appraisal process of urban centers. The finding also highlights the spatial characteristics of price-related parameters in high-density residential areas, providing an efficient evaluation approach for planning, land management, taxation, insurance, finance and other related fields."
"© 2020 by the authors.The real estate auction market has become increasingly important in the financial, economic and investment fields, but few artificial intelligence-based studies have attempted to forecast the auction prices of real estate. The purpose of this study is to develop forecasting models of real estate auction prices using artificial intelligence and statistical methodologies. The forecasting models are developed through a regression model, an artificial neural network and a genetic algorithm. For empirical analysis, we use Seoul apartment auction data from 2013 to 2017 to predict the auction prices and compare the forecasting accuracy of the models. The genetic algorithm model has the best performance, and effective regional segmentation based on the auction appraisal price improves the predictive accuracy."
"© 2019, Springer-Verlag London Ltd., part of Springer Nature.The opacity of real-estate market involves some challenges in their agent-based simulation. While some real-estate Web sites provide the prices of a great amount of houses publicly, the prices of the rest are not available. The estimation of these prices is necessary for simulating their evolution from a complete initial set of houses. Additionally, this estimation could also be useful for other purposes such as appraising houses, letting buyers know which are the best offered prices (i.e., the lowest ones compared to the appraisals) and recommending the buyers to set an initial price. This work proposes combining dimensionality reduction methods with machine learning techniques to obtain the estimated prices. In particular, this work analyzes the use of nonnegative factorization, recursive feature elimination and feature selection with a variance threshold, as dimensionality reduction methods. It compares the application of linear regression, support vector regression, the k-nearest neighbors and a multilayer perceptron neural network, as machine learning techniques. This work has applied a tenfold cross-validation for comparing the estimations and errors and assessing the improvement over a basic estimator commonly used in the beginning of simulations. The developed software and the used dataset are freely available from a data research repository for the sake of reproducibility and the support to other researchers."
"© 2019 Wiley Periodicals, Inc.Successfully predicting gentrification could have many social and commercial applications; however, real estate sales are difficult to predict because they belong to a chaotic system comprised of intrinsic and extrinsic characteristics, perceived value, and market speculation. Using New York City real estate as our subject, we combine modern techniques of data science and machine learning with traditional spatial analysis to create robust real estate prediction models for both classification and regression tasks. We compare several cutting edge machine learning algorithms across spatial, semispatial, and nonspatial feature engineering techniques, and we empirically show that spatially conscious machine learning models outperform nonspatial models when married with advanced prediction techniques such as Random Forests, generalized linear models, gradient boosting machines, and artificial neural networks."
"© 2019, Springer Science+Business Media, LLC, part of Springer Nature.Machine learning algorithms such as neural nets, support vector machines, and tree-based techniques (classification and regression trees) have shown great success in dealing with a number of complex problems (Hastie et al. 2009). However, real estate data exhibit both temporal dependence and high levels of spatial dependence (Pace et al., International Journal of Forecasting16(2), 229–246, 2000; LeSage and Pace 2009) that may make it harder to use with off-the-shelf machine learning procedures. We examine tree-based techniques (CART, boosting, and bagging) and compare these to spatiotemporal methods. We find that bagging works well and can give lower ex-sample residuals than global spatiotemporal methods, but do not perform better than local spatiotemporal methods."
"© 2021 Nicholas Johnson and Brendan Markey-Towler.This book applies cutting-edge economic analysis and social science to unpack the rich complexities and paradoxes of the Fourth Industrial Revolution. The book takes the reader on a bold, refreshing, and informative tour through its technological drivers, its profound impact on human ecosystems, and its potential for sustainable human development. The overarching message to the reader is that the Fourth Industrial Revolution is not merely something to be feared or survived; rather, this dramatic collision of technologies, disciplines, and ideas presents a magnificent opportunity for a generation of new pioneers to rewrite “accepted rules” and find new avenues to empower billions of people to thrive. This book will help readers to discern the difference between disruption and transformation. The reader will come away from this book with a deeply intuitive and highly contextual understanding of the core technological advances transforming the world as we know it. Beyond this, the reader will clearly appreciate the future impacts on our economies and social structures. Most importantly, the reader will receive an insightful and actionable set of guidelines to assist them in harnessing the Fourth Industrial Revolution so that both they and their communities may flourish. The authors do not primarily seek to make prescriptions for government policy, but rather to speak directly to people about what they can do for themselves, their families, and their communities to be future-proofed and ready to adapt to life in a rapidly evolving world ecosystem."
NULL
"© 2020, MDPI Multidisciplinary Digital Publishing Institute. All rights reserved.There is considerable hype about blockchain in almost every industry, including finance, with significant investments globally. We conduct a systematic review of 851 records and construct a final article sample of 183 for the sample period 2012 to 2020 to identify relevant factors for blockchain adoption in corporate governance. We conduct textual and empirical analysis to develop a decentralized autonomous governance framework and link traditional corporate governance theories to blockchain adoption. Furthermore, we explore present and future use cases and implications of blockchains in corporate governance. Using our systematic review and textual analysis, we further identify gaps and common trends between prior academic and industry literature. Moreover, for our empirical analysis, we compile a unique database of blockchain investments to forecast future investments. In addition, we explore blockchain potential in corporate governance during and post COVID-19. We find prior academic articles to mostly focus on regulation (49 studies) and Initial Coin Offerings (ICOs) (46 studies), while industry articles tend to concentrate on exchanges (10 studies) and cryptocurrencies (9 articles). A significant growth in literature is observed for 2017 and 2018. Finally, we provide behavioural, regulatory, ethical and managerial perspectives of blockchain adoption in corporate governance."
"© The Editor(s) (if applicable) and The Author(s) 2020.Assessing patterns and processes of plant functional, taxonomic, genetic, and structural biodiversity at large scales is essential across many disciplines, including ecosystem management, agriculture, ecosystem risk and service assessment, conservation science, and forestry. In situ data housed in databases necessary to perform such assessments over large parts of the world are growing steadily. Integrating these in situ data with remote sensing (RS) products helps not only to improve data completeness and quality but also to account for limitations and uncertainties associated with each data product. Here, we outline how auxiliary environmental and socioeconomic data might be integrated with biodiversity and RS data to expand our knowledge about ecosystem functioning and inform the conservation of biodiversity. We discuss concepts, data, and methods necessary to assess plant species and ecosystem properties across scales of space and time and provide a critical discussion of outstanding issues."
NULL
"© 2020 by Advance Scientific Research.The trend in real estate price estimation tends towards the adoption of artificial intelligence (AI) where micro variables related to real estates have been widely adopted. Whereas, macro-economic variables also have a significant role in price determination. This study, therefore, examined the trends in both micro and macro-economic variable adoption in Artificial Neural Network (ANN) related researches within the past two decades with a view to assessing their impact on the models performance. This is intended to expose the gap in the literature, in order to guide future researches in the field of AI application in price prediction. Using R2 in error measurement as a basis, the study revealed that researches that adopted macro-economic variables had 100% of the R2 values above 0.95, while studies that adopted micro variables recorded only 23% above 0.9, and 54% of their R2 to be between 0.8 to 0.9. Nevertheless, studies that adopted both variables stood at the average with 50% of their R2 readings above 0.9 and 33% was between 0.8 and 0.9. Thus, the study concludes that there is the need for future AI-related studies to explore a combination of both variables in order to avoid the two extremes."
"© 2019 IEEE.Domain names can be traded via online market places and auctions. Speculation can be lucrative, with high value transactions reaching into tens of millions of dollars. This paper proposes a framework for automated domain name appraisal and evaluates several formulations of the problem with real world data. A dynamic nonlinear valuation modelling process is defined using machine learning techniques. Attributes or value factors are derived from short domain name text strings as well as a variety of other contextual data able to be obtained online from open sources. A data set of 9.975 million domains is used for evaluation and results show that search engine query data is a primary driver of value but using extracted text features can facilitate higher performance in distinguishing high value domains particularly when used with ensemble learning."
"© 2019 by the authors.With the increasing volume and active transaction of real estate properties, mass appraisal has been widely adopted in many countries for different purposes, including assessment of property tax. In this paper, 104 papers are selected for the systematic literature review of mass appraisal models and methods from 2000 to 2018. The review focuses on the application trend and classification of mass appraisal and highlights a 3I-trend, namely AI-Based model, GIS-Based model and MIX-Based model. The characteristics of different mass appraisal models are analyzed and compared. Finally, the future trend of mass appraisal based on model perspective is defined as ""mass appraisal 2.0"": mass appraisal is the appraisal procedure of model establishment, analysis and test of group of properties as of a given date, combined with artificial intelligence, geo-information systems, and mixed methods, to better model the real estate value of non-spatial and spatial data."
"© 2019 by the authors.A recent study of property valuation literature indicated that the vast majority of researchers and academics in the field of real estate are focusing on Mass Appraisals rather than on the further development of the existing valuation methods. Researchers are using a variety of mathematical models used within the field of Machine Learning, which are applied to real estate valuations with high accuracy. On the other hand, it appears that professional valuers do not use these sophisticated models during daily practice, rather they operate using the traditional five methods. The Department of Lands and Surveys in Cyprus recently published the property values (General Valuation) for taxation purposes which were calculated by applying a hybrid model based on the Cost approach with the use of regression analysis in order to quantify the specific parameters of each property. In this paper, the authors propose a number of algorithms based on Artificial Intelligence and Machine Learning approaches that improve the accuracy of these results significantly. The aim of this work is to investigate the capabilities of such models and how they can be used for the mass appraisal of properties, to highlight the importance of sensitivity analysis in such models and also to increase the transparency so that automated valuation models (AVM) can be used for the day-to-day work of the valuer."
"© 2019 Published under licence by IOP Publishing Ltd.Nowadays in many large industrial enterprises, one of the motivational incentives for hiring employees, as well as for encouraging them, is the provision of temporary or permanent use of residential real estate. This raises the question of choosing the best option of the property from a variety of proposals on the market. This article addresses the issue of estimating the value of residential property in the city of Krasnoyarsk. The descriptive signs of the apartment were not only its internal parameters, such as the area or number of rooms, but also the external characteristics that describe the environment of the apartment house. The data on the apartments were taken from the website of the apartment sales announcements and from various open data sources. The number of organizations of each type considered within a radius of 1000 m serves as a quantitative measure of the house environment. The model built using a random forest showed good results and solved the problem. The relative error of the forecast was 8%. In addition, it was shown the positive impact of the apartment external characteristics on the quality of the constructed model. As a result, an easily scalable model was built that can be applied to other cities."
"© 2019, Springer Science+Business Media, LLC, part of Springer Nature.The geographical presentation of a house, which refers to the sightseeing and topography near the house, is a critical factor to a house buyer. The street map is a type of common data in our daily life, which contains natural geographical presentation. This paper sources real estate data and corresponding street maps of houses in the city of Los Angeles. In the case study, we proposed an innovative method, attention-based multi-modal fusion, to incorporate the geographical presentation from street maps into the real estate appraisal model with a deep neural network. We firstly combine the house attribute features and street map imagery features by applying the attention-based neural network. After that, we apply boosted regression trees to estimate the house price from the fused features. This work explored the potential of attention mechanism and data fusion in the applications of real estate appraisal. The experimental results indicate the competitiveness of proposed method among state-of-the-art methods."
"© 2019, The Author(s).This paper formulates a protocol for prediction of packs, which is a special case of on-line prediction under delayed feedback. Under the prediction of packs protocol, the learner must make a few predictions without seeing the respective outcomes and then the outcomes are revealed in one go. The paper develops the theory of prediction with expert advice for packs by generalising the concept of mixability. We propose a number of merging algorithms for prediction of packs with tight worst case loss upper bounds similar to those for Vovk’s Aggregating Algorithm. Unlike existing algorithms for delayed feedback settings, our algorithms do not depend on the order of outcomes in a pack. Empirical experiments on sports and house price datasets are carried out to study the performance of the new algorithms and compare them against an existing method."
"© 2019 The AuthorsData standardization is recognized in many disciplines as a critical aspect of data stewardship. Establishing and implementing data specifications increases the usefulness of data collection efforts and facilitates analysis techniques. With the advent of large quantities of machine-generated data, the use of standardized data formats feeds opportunities for visualization and advanced applications with machine-learning and Artificial Intelligence (AI). The transportation industry made substantial progress with data format specifications in the late 1990s, primarily for highway traffic. Unfortunately, establishing data standards has been an on-going challenge for the transit community. Archived Intelligent Transportation Systems (ITS) transit data (e.g., Automatic Vehicle Location (AVL), Automatic Passenger Counters (APCs), Automatic Fare Card (AFC)) still lack industry standards for data formats. Recent advancements in electronic transit scheduling (e.g., General Transit Feed Specifications (GTFS)) met a portion of this challenge with Open Data specifications. Now GTFS provides transit riders with agile information on services available at any location where the data is provided to developers of mobile device application (apps). Due to system and vendor limitations, the Metropolitan Transportation Authority (MTA), serving the New York City region, publishes its real-time subway system data in GTFS-R and its bus data in SIRI. This research develops an Application Programming Interface (API) to translate GTFS-R into SIRI to overcome the lack of standards making it possible to harmonize the subway and bus systems for the New York region. This solution offers the opportunity to develop a novel set of analytical tools, including pseudo-surveillance data for performance metrics."
"© 2019 Jacek Zyga, published by Sciendo.In the course of discussion on an econometric model of property value and its place in property appraisal, the argument of the main goal of the process (property market value prediction itself) was raised in this article. The need for the consideration of an ontologically perceived, particular element of the real estate market with its distinctive characteristics indicates the specific nature of the interpretation of the data which may be used in the appraisal process. Therefore, a new shape of the property value model, based on LSM, was presented. It takes into account a specific description of the appraised property. Thus, the factor of dissimilarity between sold properties used in creating the value model and the appraised property was used in its coefficient matrix. The new model clearly shows the advantages and disadvantages of the dissimilarities between sold properties used in creating the coefficient matrix of the value model."
"© 2019 by the authors.The present research takes into account the current and widespread need for rational valuation methodologies, able to correctly interpret the available market data. An innovative automated valuation model has been simultaneously implemented to three Italian study samples, each one constituted by two-hundred residential units sold in the years 2016-2017. The ability to generate a ""unique"" functional form for the three different territorial contexts considered, in which the relationships between the influencing factors and the selling prices are specified by different multiplicative coefficients that appropriately represent the market phenomena of each case study analyzed, is the main contribution of the proposed methodology. The method can provide support for private operators in the assessment of the territorial investment conveniences and for the public entities in the decisional phases regarding future tax and urban planning policies."
"© 2019 Elsevier LtdObjective monitoring of the real estate value is a requirement to maintain balance, increase security and minimize the risk of a crisis in the financial and economic sector of every country. The valuation of real estate is usually considered from two points of view, i.e. individual valuation and mass appraisal. It is commonly believed that Automated Valuation Models (AVM) should be devoted to mass appraisal, which requires a large size of databases (wider knowledge) and automated procedures. These models, however, have a wider spectrum of application. The main aim of the study is to elaborate on a decision-making algorithm in the form of an Automated Valuation Model that uses the assumptions of the decision-making theory and data mining technology (Rough Set Theory (RST) and Value Tolerance Relation (VTR) - Fuzzy logic). The algorithm gives the opportunity to obtain the value of real estate where, using “if…then…” rules, we can account for the possibility of a non-deterministic relationship between real estate variables. It is applied to a small dataset of commercial real estate properties in Italy and residential ones in Poland. The proposed solution is universal and may be used in any other domain with imprecise and vague data."
"© 2019 Elsevier B.V.Uncovering the structure of socioeconomic systems and timely estimation of socioeconomic status are significant for economic development. The understanding of socioeconomic processes provides foundations to quantify global economic development, to map regional industrial structure, and to infer individual socioeconomic status. In this review, we will make a brief manifesto about a new interdisciplinary research field named Computational Socioeconomics, followed by detailed introduction about data resources, computational tools, data-driven methods, theoretical models and novel applications at multiple resolutions, including the quantification of global economic inequality and complexity, the map of regional industrial structure and urban perception, the estimation of individual socioeconomic status and demographic, and the real-time monitoring of emergent events. This review, together with pioneering works we have highlighted, will draw increasing interdisciplinary attentions and induce a methodological shift in future socioeconomic studies."
"© 2019 by the authors.The cogency of evaluationmodels able topredict future trends andtomonitor the consequences of scenarios different from those initially expected has been determining a growing scientific interest for the development of financial sustainability methods. With reference to quarterly time series collected for the metropolitan area of five Spanish cities, in this research an innovative methodology has been implemented, in order to make explicit, for each case study, the main functional relationships between the housing prices and the socio-economic factors. The models obtained are characterized by both high statistical performance and compliance with the expected market phenomena, highlighting the decisive role in the housing price formation of the factors that indirectly represent the population's income capacity (market rents, unemployment level, mortgages). Then, an empirical procedure for the construction of the future property value trends has been developed. The results point out the forecasting and monitoring potentialities of the methodology used, as a fundamental decision support tool in the urban planning policies of the local administrations, interested in anticipating and checking future housing bubbles through appropriate economic policies, and for private operators, in the phases of selection of the most attractive territorial areas for new property realizations."
"© 2019 by the authors.Land development in sub-urban areas is more frequent than in highly urbanized cities, causing land prices to increase abruptly and making it harder for valuers to update land values in timely manner. Apart from this, the non-availability of sufficient reliable market values forces valuers to use alternatives and subjective judgement. Land value is critical not only for private individuals but also for government agencies in their day-to-day land dealings. Thus, mass appraisal is necessary. In other words, despite the importance of reliable land value in all aspects of land administration, valuation remains disorganized, with unregulated undertakings that lack concrete scientific, legal, and practical foundations. A holistic and objective way of weighing geospatial factors through expert consultation, legal reviews, and evidence (i.e., news) will provide more realistic results than a regression-based method that does not comprehend valuation factors (i.e., physical, social, economic, environmental, and legal aspects). The analytic hierarchy process (AHP) enables these factors to be included in the model, hence providing a realistic result. The innovative land valuation model (iLVM), developed in this study, is an inclusive approach wherein experts are involved in the selection and weighing of 15 factors through the AHP. The model was validated using root mean squared error (RMSE) and compared with multiple regression analysis (MRA) through a case study in Baybay City, Philippines. Based on the results, the iLVM (RMSE = 0.526) outperformed MRA (RMSE = 1.953)."
"© 2019, Emerald Publishing Limited.Purpose: The purpose of this study is to discover the distribution and trends of existing Offsite construction (OSC) literature with an intention to highlight research niches and propose the future outline. Design/methodology/approach: The paper adopted literature reviews methodology involving 1,057 relevant documents published in 2008-2017 from 15 journals. The selected documents were empirically analyzed through a topic-modeling technique. A latent Dirichlet allocation model was applied to each document to infer 50 key topics. A machine learning for language toolkit was used to get topic posterior word distribution and word composition. Findings: This is an exploratory study, which identifies the distribution of topics and themes; the trend of topics and themes; journal distribution trends; and comparative topic, themes and journal distribution trend. The distribution and trends show an increase in researcher’s interest and the journal’s priority on OSC research. Nevertheless, OSC existing literature is faced with; under-researched topics such as building information modeling, smart construction and marketing. The under-researched themes include organizational management, supply chain and context. The authors also found an overload of similar information in prefabrication and concrete topics. Furthermore, the innovative methods and constraints themes were found to be overloaded with similar information. Research limitations/implications: The naming of the themes was based on our own interpretation; hence, the research results may lack generalizability. Therefore, a comparative study using different data processing is proposed. The study also provides future research outline as follows: studying OSC topics from dynamic evolution perspective and identifying the new emerging topics; searching for effective strategies to enhance OSC research; identifying the contribution of countries, affiliation and funding agency; and studying the impact of these themes to the adoption of OSC. Practical implications: This study is of values to the scholars, as it could stimulate research to under-researched areas. Originality/value: This paper justifies a need to have a broad understanding of the nature and structure of existing OSC literature."
"© 2019 by the authors.The evaluation of real estate assets is currently one of the main focal points addressed by territorial marketing strategies, with the view of developing high-performing or competitive cities. Given the complexity of the driving forces that determine the behavior of actors in a real estate market, it is necessary to identify a priori the factors that determine the competitive capacity of a city, to attract investments. The decision support system allows taking into account the key factors that determine the ""attractiveness"" of real estate investments in competitive urban contexts. This study proposes an integrated complex evaluation model that is able to map out and encapsulate the multidimensional spectrum of factors that shape the attractiveness of alternative real estate options. The conceptual-methodological approach is illustrated by an application of the model to a real-world case study of investment choice in the residential sector of Naples."
"© 2019 by the authors.This article aims at testing the possibilities of applying hierarchical spatial autoregressive models to create land value maps in urbanized areas. The use of HSAR (Hierarchical Spatial Autoregressive) models for spatial differentiation of prices in the property market supports the multilevel diagnosis of the structure of this phenomenon, taking into account the effect of spatial interactions. The article applies a two-level hierarchical spatial autoregressive model, which will permit the evaluation of interactions and control spatial heterogeneity at two levels of spatial aggregation (general and detailed). The results of the research include both the evaluation of the impact of location on prices (taking into account non-spatial factors) and the creation of the average land price map, taking into consideration the spatial structure of the city. In empirical studies, the HSAR model was compared with classic LM (Linear Model), HLM (Hierarchical Linear Model), and SAR (Spatial Autoregressive) models to perform comparative analyses of the results."
"© 2019, Emerald Publishing Limited.Purpose: The purpose of this paper is to investigate the accuracy and volatility of different methods for estimating and updating hedonic valuation models. Design/methodology/approach: The authors apply six estimation methods (linear least squares, robust regression, mixed-effects regression, random forests, gradient boosting and neural networks) and two updating methods (moving and extending windows). They use a large and rich data set consisting of over 123,000 single-family houses sold in Switzerland between 2005 and 2017. Findings: The gradient boosting method yields the greatest accuracy, while the robust method provides the least volatile predictions. There is a clear trade-off across methods depending on whether the goal is to improve accuracy or avoid volatility. The choice between moving and extending windows has only a modest effect on the results. Originality/value: This paper compares a range of linear and machine learning techniques in the context of moving or extending window scenarios that are used in practice but which have not been considered in prior research. The techniques include robust regression, which has not previously been used in this context. The data updating allows for analysis of the volatility in addition to the accuracy of predictions. The results should prove useful in improving hedonic models used by property tax assessors, mortgage underwriters, valuation firms and regulatory authorities."
"© 2019, Emerald Publishing Limited.Purpose: The purpose of this paper is to examine the features and tendency of cost indices in the global construction setting. Design/methodology/approach: Data from 22 countries/regions are collected and analyzed using maximum variance formulation and Kendall rank correlation coefficient. Findings: It is found that global construction cost indexes (CCIs) have commonly maintained a steady increase for decades, and the CCIs synchronize with each other. Overall synchronicity and synchronicity of different countries pairs have increased with time significantly. Research limitations/implications: The major limitation, however, is the availability of data: only 22 regions/countries are examined, the distribution of these regions/countries is imbalanced between different continents and various indices are adopted around the world, of which statistical methods are not same. Practical implications: The implication is that a better perception of CCIs enables contractors to have a robust estimation for bidding prices and to improve the efficiency of construction projects management. The research findings also provide a useful reference for those countries that have not established construction cost indices databases to forecast the tendency of domestic construction industries. Originality/value: This paper contributes to the overall body of knowledge by presenting the co-movement of global CCIs and measuring the changes of CCI synchronicity with time and in different countries pairs."
"© 2018 IEEE.Housing costs have a significant impact on individuals, families, businesses, and governments. Recently, online companies such as Zillow have developed proprietary systems that provide automated estimates of housing prices without the immediate need of professional appraisers. Yet, our understanding of what drives the value of houses is very limited. In this paper, we use multiple sources of data to entangle the economic contribution of the neighborhood's characteristics such as walkability and security perception. We also develop and release a framework able to now-cast housing prices from Open data, without the need for historical transactions. Experiments involving 70,000 houses in 8 Italian cities highlight that the neighborhood's vitality and walkability seem to drive more than 20% of the housing value. Moreover, the use of this information improves the nowcast by 60%. Hence, the use of property's surroundings' characteristics can be an invaluable resource to appraise the economic and social value of houses after neighborhood changes and, potentially, anticipate gentrification."
"© Cambridge University Press 2019.Towns and villages are sometimes viewed as minor, even quaint, spots, whereas this book boldly reconceptualizes these places as important dynamic environmental 'hotspots'. Multitudes of towns and villages with nearly half the world's population characterize perhaps half the global land surface. The book's pages feature ecological patterns, processes, and change, as well as human dimensions, both within towns and in strong connections and effects on surrounding agricultural land, forest land, and arid land. Towns, small to large, and villages are examined with spatial and cultural lenses. Ecological dimensions - water, soil and air systems, together with habitats, plants, wildlife and biodiversity - are highlighted. A concluding section presents concepts for making better towns and better land. From a pioneer in both landscape ecology and urban ecology, this highly international town ecology book opens an important frontier for researchers, students, professors, and professionals including environmental, town, and conservation planners."
NULL
"© 2019 American Real Estate and Urban Economics AssociationWithin-city house prices can be a very complicated system, in which the local prices may significantly differ in both levels and changes and diffuse across locations. These issues are essential for understanding and interpreting the dynamics of city-level housing markets. In this study, we construct a constant-quality spatiotemporal price index for Beijing's resale housing market between 2011 and 2015, which serves as a common basis for our multi-perspective and comprehensive analysis on within-city house price patterns. As suggested by the spatial distribution and local structures, the local price levels are not homogeneous or fully amenable to a simple structure. The local price changes, likewise, are not synchronized in terms of either price trend or structural breakpoint. However, the within-city house prices still display clear patterns. The local price levels, trends and breakpoints can be partially explained by local amenities or socioeconomic factors and the local price changes diffuse between neighboring areas. These findings deliver deep insights into within-city housing markets and have important implications for urban planning and housing investment."
"© Springer Nature Singapore Pte Ltd. 2019.Most existing real estate appraisal methods focus on building accuracy and reliable models from a given dataset but pay little attention to the extensibility of their trained model. As different cities usually contain a different set of location features (district names, apartment names), most existing mass appraisal methods have to train a new model from scratch for different cities or regions. As a result, these approaches require massive data collection for each city and the total training time for a multi-city property appraisal system will be extremely long. Besides, some small cities may not have enough data for training a robust appraisal model. To overcome these limitations, we develop a novel Homogeneous Feature Transfer and Heterogeneous Location Fine-tuning (HFT+HLF) cross-city property appraisal framework. By transferring partial neural network learning from a source city and fine-tuning on the small amount of location information of a target city, our semi-supervised model can achieve similar or even superior performance compared to a fully supervised Artificial neural network (ANN) method."
"© Springer International Publishing AG, part of Springer Nature 2019.Market information on housing is relevant for good decision making of households as well as for real estate economics and is also of systemic interest. The official statistics often provide only annual indices on national level based on transactions of previous year. The stakeholders of the real estate markets however request analysis of higher spatial resolution on local level based recent transactions. This paper focuses on methodology of automated data acquisition, analysis and visualization of data from the housing market. Data retrieved from observing real estate markets (to rent/to buy) are used for statistical modelling of value-descriptive parameters, for estimating and forecasting real estate market fundamentals, which also can reveal market risks. This paper elaborates methods of automated data acquisition based on web mining, reviews methods of econometric spatial modelling with impact from proximity in order to deduct efficiency parameters within different categories. The analysis and the resulting visualization at different granularity of spatial, temporal and typological effects provides relevant information for decision making."
"© Springer International Publishing AG, part of Springer Nature 2019.In this paper a hedonic price function built through a semiparametric additive model is tried out for the real estate market analysis of the central area of Reggio Calabria. The semiparametric model uses Penalized Spline functions and aims to achieve an improvement in the prediction of the market prices of housing properties in the central area of Reggio Calabria. More in particular, the final objective of the research is to detect and to identify possible potential market premium in real estate exchange and rent markets for green buildings. This is the first preliminary phase for the unavoidable verification of the robustness of the real estate sample, or for the subsequent individuation of progressive real estate sub-samples."
"© Springer International Publishing AG, part of Springer Nature 2019.Geographically Weighted Regression is a statistical technique for real estate market analysis, particularly adequate in order to identify homogeneous areas and to define the marginal contribution that the geographical location gives to the market value of the properties. In this paper a GWR has been applied, in order to verify the robustness of the real estate sample, this for the subsequent individuation of progressive real estate sub-samples in able to detect and to identify possible potential market premium in real estate exchange and rent markets for green buildings [21–28]. The model has been built on a large real estate dataset, related to the trades of residential real estate units in the city of Reggio Calabria (Calabria region, Southern Italy)."
"© Springer International Publishing AG, part of Springer Nature 2019.Generally, with reference to the geographical variability of real estate values, the observed variables may have non-linear relationships with the response variable. For this reason it’s possible to combine kriging techniques with additive models to obtain the geoadditive models. In this paper a geoadditive model based on penalized spline functions has been applied, in order to obtain improvements respect to usual Kriging techniques and to provide a spatial distribution of real estate unitary values for a central area of the city of Reggio Calabria (Italy). This is the first preliminary phase for the verification of the robustness of the real estate sample, or for the subsequent individuation of progressive real estate sub-samples, for to detect and to identify possible potential market premium in real estate exchange and rent markets for green buildings."
"© The Author(s). 2018.Background: The distribution of forest vegetation within urban environments is critically important as it influences urban environmental conditions and the energy exchange through the absorption of solar radiation and modulation of evapotranspiration. It also plays an important role filtering urban water systems and reducing storm water runoff. Methods: We investigate the capacity of ALS data to individually detect, map and characterize large (taller than 15 m) trees within the City of Vancouver. Large trees are critical for the function and character of Vancouver’s urban forest. We used an object-based approach for individual tree detection and segmentation to determine tree locations (position of the stem), to delineate the shape of the crowns and to categorize the latter either as coniferous or deciduous. Results: Results indicate a detection rate of 76.6% for trees > 15 m with a positioning error of 2.11 m (stem location). Extracted tree heights possessed a RMSE of 2.60 m and a bias of − 1.87 m, whereas crown diameter was derived with a RMSE of 3.85 m and a bias of − 2.06 m. Missed trees are principally a result of undetected treetops occurring in dense, overlapping canopies with more accurate detection and delineation of trees in open areas. Conclusion: By identifying key structural trees across Vancouver’s urban forests, we can better understand their role in providing ecosystem goods and services for city residents."
"© 2018, The Author(s).Introduction: Mass appraisals in the rental housing market are far less common than those in the sales market. However, there is evidence for substantial growth in the rental market and this lack of insight hampers commercial organisations and local and national governments in understanding this market. Case description: This case study uses data that are supplied from a property listings web site and are unique in their scale, with over 1.2 million rental property listings available over a 2 year period. The data is analysed in a large data institute using generalised linear regression, machine learning and a pseudo practitioner based approach. Discussion and evaluation: The study should be seen as a practical guide for property professionals and academics wishing to undertake such appraisals and looking for guidance on the best methods to use. It also provides insight into the property characteristics which most influence rental listing price. Conclusions: From the regression analysis, attributes that increase the rental listing price are: the number of rooms in the property, proximity to central London and to railway stations, being located in more affluent neighbourhoods and being close to local amenities and better performing schools. Of the machine learning algorithms used, the two tree based approaches were seen to outperform the regression based approaches. In terms of a simple measure of the median appraisal error, a practitioner based approach is seen to outperform the modelling approaches. A practical finding is that the application of sophisticated machine learning algorithms to big data is still a challenge for modern desktop PCs."
"© 2019 John Wiley & Sons Ltd.Thoroughly revised and updated, the second edition, Environmental Psychology: An Introduction offers an overview of the interplay between humans and their environments. The text examines the influence of the environment on human experiences, behaviour and well-being and explores the factors influencing environmental behaviour, and ways to encourage pro-environmental behaviour. The revised edition is a state-of-the art review of relevant theories and research on each of these topics. With contributions from an international panel of noted experts, the text addresses a wealth of topics including the main research methods in environmental psychology; effects of environmental stress; emotional impacts and meanings of natural environment experience; aesthetic appraisals of architecture; how to measure environmental behaviour; cognitive, emotional and social factors explaining environmental behaviour; effects and acceptability of strategies to promote pro-environmental factors; and much more. This important book: • Discusses the environmental factors that threaten and promote human wellbeing • Explores a wide range of factors influencing actions that affect environmental conditions • Discusses the effects and acceptability of approaches that aim to encourage pro-environmental behavior • Presents research results conducted in different regions in the world • Contains contributions from noted experts Written for scholars and practitioners in the field, the revised edition of Environmental Psychology offers a comprehensive review of the most recent research available in environmental psychology."
"© 2017, Springer-Verlag Berlin Heidelberg.Estates with short days-on-market (DOM), referring to the properties whose days on the active market are short, attract realtors to gain commission quickly in transactions. With the rise of the Internet, massive information of on-sale houses can be obtained online. It is a challenge for estate agencies to mine estates with short DOM from such massive information. In this paper, we proposed an estate with short DOM appraisal framework to automatically recommend those estates using transaction data and profile information crawled from websites. Motivated by the estimation process of domain experts, we first seek similar estates with the location, structure and market information of estates. Then, the listing prices of similar estates were used to calculate a price interval. To evaluate the proposed framework, we used two real-world datasets, which consist of 220,000 on-sale estates and 643 estates with manually evaluated values in Chongqing real estate market. The results show that the proposed framework can estimate accurately about 78% estates. Two agencies scored the list of recommendation, in which 88% estates are trustworthy. Compared to the classical hedonic model, our method can successfully deal with problems such as the negative effects of special estates and the lack of labels. Moreover, both the spatial and temporal characteristics of an estate are integrated into our framework. The effect of different parameter settings is also discussed."
"© 2018, Emerald Publishing Limited.Purpose: As regards the assessment of the market values of properties that compose real estate portfolios, the purpose of this paper is to propose and test an automated valuation model. In particular, the method defined allows for providing for objective, reliable and “quick” valuations of the assets in the phases of periodic reviews of the property values. Design/methodology/approach: Aiming at both predictive and interpretative purposes, the method, based on multi-objective genetic algorithms to search those model expressions that simultaneously maximize the accuracy of the data and the parsimony of the mathematical functions, is applied to a sample data of office properties characterized by medium and large size, located in the city of Milan (Italy) and sold in the period between 2004 and 2015. Findings: The model obtained could be an integration of the canonical methodologies (market approach, income approach, cost approach) implemented in the assessment of the market values of properties, so as to provide an additional tool to verify the results. In particular, the inclusion of economic variables in the model is consistent with the need to reiterate the valuations, contextualizing them to the locational characteristics and to the current property cycle phase in the specific area. Practical implications: The model can be applied by all the operators involved in the periodic reviews of the values of property portfolios: from real estate funds’ insiders, in order to monitor the values obtained through the canonical approaches, to the public institutions, such as the revenue agencies, in order to ensure the fair payment of the taxes through the updating values of the properties according to the actual and current market trends. Originality/value: The method proposed can be a valid support for all public and private entities that hold significant property assets and that, for various reasons (periodic reviews of the balance sheets, sales, enhancement, investment, etc.), require cyclical updated values of the properties. The automated valuation model developed can be used for the assessment of “comparison” values with the estimates values obtained by other assessment techniques, in order to ensure a further monitoring tool of the results from the subjects involved."
"© 2018 American Society of Civil Engineers.How to know the price of residential land located at a mine subsidence site is still a critical consideration for land transaction and development. Typically, a mining area inevitably faces a series of environmental issues, but the quantitative measurement is inadequately reported all over the world, mostly focused on contaminated land. However, the effect of mining-induced surface deformation on residential land price is the concern in this paper, and the Nanhu Ecoregion, a typical mine subsidence site in China, was taken as a study case. Based on a careful comparison of potential geological risks, five critical determinants were selected to evaluate the suitability for bearing capacity of building foundations. By sampling plots, the average price of residential plots within suitability classes was estimated to couple with two characteristic factors-floor area ratio and building height. Finally, the negative and positive changes in residential land price were obtained. The results show that the potential geological risks caused by mining activities determine the formation and fluctuation of residential land price, closely related to the change of characteristic factors, and that mining activities induce an approximate 20% reduction of land price caused by the damage of site conditions. Also, the Nanhu Ecoregion benefits from a 15% increase in land price from ecological welfare created by a mine subsidence-induced wetland landscape. This study is aimed at assisting stakeholders' decision making."
"© 2018 by the authors.Applied to real estate markets analysis, the resampling methods aim to contribute to the knowledge growth of real estate market dynamics, overcoming the issues related to the data scarcity and operational limits of traditional statistical theory. Among resampling methods, the Bootstrap technique appears to be the most suitable for the interpretation of real estate phenomena. In this study, for residential properties located in Cosenza (Calabria Region, Italy), a Bootstrap approach has been used in order to determine the marginal prices of the real estate characteristics detected, comparing the results with those obtainable with a traditional Multiple Regression Analysis."
"© 2018, Emerald Publishing Limited.Purpose: The paper aims to investigate the application of particle swarm optimisation and back propagation in weights optimisation and training of artificial neural networks within the mass appraisal industry and to compare the performance with standalone back propagation, genetic algorithm with back propagation and regression models. Design/methodology/approach: The study utilised linear regression modelling before the semi-log and log-log models with a sample of 3,242 single-family dwellings. This was followed by the hybrid systems in the selection of optimal attribute weights and training of the artificial neural networks. Also, the standalone back propagation algorithm was used for the network training, and finally, the performance of each model was evaluated using accuracy test statistics. Findings: The study found that combining particle swarm optimisation with back propagation in global and local search for attribute weights enhances the predictive accuracy of artificial neural networks. This also enhances transparency of the process, because it shows relative importance of attributes. Research limitations/implications: A robust assessment of the models’ predictive accuracy was inhibited by fewer accuracy test statistics found in the software. The research demonstrates the efficacy of combining two models in the assessment of property values. Originality/value: This work demonstrated the practicability of combining particle swarm optimisation with back propagation algorithms in finding optimal weights and training of the artificial neural networks within the mass appraisal environment."
"© 2018, Saudi Society for Geosciences.Geo-statistics techniques showed high applicability in fields related to geotechnical engineering like mining and petroleum engineering. Hence, this paper introduces direct application of Geo-statistics in Geotechnical engineering which is 3D soil profiling. It introduces Geo-statistics as a concept and shows the practical implementation of these techniques on modeling soil profile using CPT sample data through the integration between GIS and a specialized 3D Geo-statistical modeling software called Sgems (Stanford Geo-statistical modeling software). Using 30 CPT logs in Sabkha soil from the data of Soil Works for a costal Housing Project located approximately 25 km west of Kuwait city, and a semi-automated workflow, the 3D model was produced on Sgems and converted to GIS. The ESRI-ArcGIS software was used in querying 3D soil profile and in producing 3D section in-spite of its limitation in 3D Voxel representation."
"© 2018 Walter de Gruyter GmbH, Berlin/Boston 2018.This paper focuses on the problem of quantifying how certain words in a text affect, positively or negatively, some numeric signal. These words can lead to important decisions for significant applications such as E-commerce. For example, consider the corpus of real-estate classifieds, which we developed as a case study. Each classified has a description of a real-estate property, along with simple features such as the location and the number of bedrooms. The problem then is to identify which keywords influence the price of the property. Such identification is complicated due to the existence of simple features (numeric and nominal attributes) that also affect the price. In this research, we propose a two-stage regression model to solve this problem. To assess our contribution, we analyze, as a case study, four corpora of real-estate classifieds. The analysis shows that our model predicts the price of a real-estate unit more accurately using the accompanying text, compared to the prediction relying only on simple features. We also demonstrate the capability of our model to annotate (automatically) words that affect the price positively or negatively."
"© 2018, Springer International Publishing AG, part of Springer Nature.Purpose of Review: Recent development of energy big data could potentially transform existing energy efficiency evaluation studies into more accurate, generalizable, and scalable ones. This review article covers existing residential energy efficiency evaluation studies and residential building energy studies. Recent Findings: Results reveal that the majority of existing energy efficiency evaluation frameworks and traditional statistical analysis are not sufficient enough to identify the causal impact of energy efficiency. In reality, households mostly self-select into energy efficiency installations and the observed changes in energy consumption after the installations may be due, at least in part, to certain factors that are generally time-variant and unobservable to the statistician. Summary: Researchers can utilize emerging large-scale building energy datasets combined with high-frequency energy demand data to develop innovative computational energy efficiency evaluation frameworks. Such frameworks should incorporate knowledge and advances from various disciplines including machine learning, statistics, and econometrics in order to provide more accurate and information-rich causal impact evaluations of energy efficiency measures."
"© 2019 Elsevier Ltd. All rights reserved.Electronic Enclosures, Housings and Packages considers the problem of heat management for electronics from an encasement perspective. It addresses enclosures and their applications for industrial electronics, as well as LED lighting solutions for stationary and mobile markets. The book introduces fundamental concepts and defines dimensions of success in electrical enclosures. Other chapters discuss environmental considerations, shielding, standardization, materials selection, thermal management, product design principles, manufacturing techniques and sustainability. Final chapters focus on business fundamentals by outlining successful technical propositions and potential future directions."
NULL
"Copyright © 2018 Inderscience Enterprises Ltd.The purpose of this research is to analyse the performance of a real estate valuation model based on the multi objective decision making methods. The optimal price function is achieved with the goal programming model. The price function which is described as the sum of the individual objectives (criteria), and the goals are the prices of comparable properties. The model integrates with the inductive and deductive approach overcomes many of the assumptions of the best known statistical approaches. The evaluation of the proposed model is performed by comparing the results obtained by the application, to the same case study, of a multiple linear regression model and a nonlinear regression method based on penalised spline smoothing model. The comparison shows, first of all, the best interpretation capabilities of the proposed model."
"© Springer Nature Switzerland AG 2018.Property valuation is a complex and time-consuming process which is carried out by qualified real estate appraisers. Number of properties and number of purchase-sale transactions grows year by year. Mass real estate appraisal appears as another big problem. These issues are connected with deficiency of human and time resources. Therefore, numerous studies are carried out on computer systems which can support the real estate appraisers. Automated property valuation systems are also developed. A method utilizing clustering algorithms to automate property valuation according to sales comparison approach was proposed in this paper. A crisp and fuzzy clustering algorithms were employed to divide the properties located in a given city into a number of clusters. These clusters established the basis for property valuation process. The effectiveness of the proposed method was examined and compared with the real estate appraisal based on the spatial partition of an area of the city into cadastral regions and expert zones."
NULL
"© 2017 by the authors.This paper experiments an artificial neural networks model with Bayesian approach on a small real estate sample. The output distribution has been calculated operating a numerical integration on the weights space with the Markov Chain Hybrid Monte Carlo Method (MCHMCM). On the same real estate sample, MCHMCM has been compared with a neural networks model (NNs), traditional multiple regression analysis (MRA) and the Penalized Spline Semiparametric Method (PSSM). All four methods have been developed for testing the forecasting capacity and reliability of MCHMCM in the real estate field. The Markov Chain Hybrid Monte Carlo Method has proved to be the best model with an absolute average percentage error of 6.61%."
"© 2017 Tom Kauko. All Rights Reserved.Urban sustainability has become a political and social agenda of global significance, of which real estate is an integral dimension. Sustainable urban development includes much more than 'green building' standards, yet in practice, other aspects such land use plans and locations are often overlooked. This book demonstrates that the issue of sustainable development stretches far beyond the hitherto dominating agenda based on 'green' (i.e. environmentally and ecologically sustainable) buildings. In doing so, it presents a novel framework based on the concept of economic sustainability of real estate locations, drawing connections with the global financial crisis and housing price bubble discourse. It argues for the need to better integrate social, cultural and economic dimensions into the real estate sustainability. agenda. It also explores the role of location, and especially the image aspect therein. Trends in consumer choice are important to the way these dimensions are appreciated in decisions about investment, development, valuation and other activities of the production, consumption and governance of the built environment. This book will be of interest to private and public sector practitioners of real estate valuation as well as scholars of urban studies, geography, economics, urban planning and environmental studies."
"© 2017 by the authors. Licensee MDPI, Basel, Switzerland.Nowadays, there is growing interest in all the smart technologies that provide us with information and knowledge about the human environment. In the energy field, thanks to the amount of data received from smart meters and devices and the progress made in both energy software and computers, the quality of energy models is gradually improving and, hence, also the suitability of Energy Conservation Measures (ECMs). For this reason, the measurement of the accuracy of building energy models is an important task, because once the model is validated through a calibration procedure, it can be used, for example, to apply and study different strategies to reduce its energy consumption in maintaining human comfort. There are several agencies that have developed guidelines and methodologies to establish a measure of the accuracy of these models, and the most widely recognized are: ASHRAE Guideline 14-2014, the International Performance Measurement and Verification Protocol (IPMVP) and the Federal Energy Management Program (FEMP). This article intends to shed light on these validation measurements (uncertainty indices) by focusing on the typical mistakes made, as these errors could produce a false belief that the models used are calibrated."
"© 2017, The Author(s).Accurate property valuation is important for property purchasers, investors and for mortgage-providers to assess credit risk in the mortgage market. Automated valuation models (AVM) are being developed to provide cheap, objective valuations that allow dynamic updating of property values over the term of a mortgage. A useful feature of automated valuations is to provide a region of plausible price estimates for each individual property, rather than just a single point estimate. This would allow buyers and sellers to understand uncertainty on pricing individual properties and mortgage providers to include conservatism in their credit risk assessment. In this study, Conformal Predictors (CP) are used to provide such region predictions, whilst strictly controlling for predictive accuracy. We show how an AVM can be constructed using a CP, based on an underlying k-nearest neighbours approach. Time trend in property prices is dealt with by assuming a systematic effect over time and adjusting prices in the training data accordingly. The AVM is tested on a large data set of London property prices. Region predictions are shown to be reliable and the efficiency, ie region width, of property price predictions is investigated. In particular, a regression model is constructed to model the uncertainty in price prediction linked to property characteristics."
"© 2018 John Wiley & Sons Ltd. All rights reserved.A new framework for understanding the underpinnings of real estate property value and the role it plays in the larger economy. Value in a Changing Built Environment examines the professional foundations on which the valuation exercise and the valuation profession rest. Written by noted experts in the field, the book addresses the often limited understanding of the concept of property value by explaining the intrinsic linkages between economic, environmental, social, and cultural measures and components of property value. The book offers a framework that paves the way towards a more holistic approach to property value. Value in a Changing Built Environment unwraps many of the traditional assumptions that have underpinned market participants' decision making over the last few decades. The authors explore the concept that a blindfold application of valuation theories and approaches adopted from finance is unlikely to be able to cope with the nature of property as an economic and public good. This vital resource: Explains the criteria for making estimates of value that can be applied worldwide; Offers an integrated approach to property value and the valuation processes; Captures the often illusive intangibles such as environmental performance into valuation; Addresses a market failure to account for wider criteria on building performance. Value in a Changing Built Environment examines how real estate valuation plays a pivotal role in decision making and how can a new body of knowledge improve the practice in both business and social domains."
"© 2017, Global Institute of Flexible Systems Management.The importance of data science and big data analytics is growing very fast as organizations are gearing up to leverage their information assets to gain competitive advantage. The flexibility offered through big data analytics empowers functional as well as firm-level performance. In the first phase of the study, we attempt to analyze the research on big data published in high-quality business management journals. The analysis was visualized using tools for big data and text mining to understand the dominant themes and how they are connected. Subsequently, an industry-specific categorization of the studies was done to understand the key use cases. It was found that most of the existing research focuses majorly on consumer discretionary, followed by public administration. Methodologically, a major focus in such exploration is in social media analytics, text mining and machine learning applications for meeting objectives in marketing and supply chain management. However, it was found that not much focus was highlighted in these studies to demonstrate the tools used for the analysis. To address this gap, this study also discusses the evolution, types and usage of big data tools. The brief overview of big data technologies grouped by the services they enable and some of their applications are presented. The study categorizes these tools into big data analysis platforms, databases and data warehouses, programming languages, search tools, and data aggregation and transfer tools. Finally, based on the review, future directions for exploration in big data has been provided for academic and practice."
"© 2017 Vilnius Gediminas Technical University (VGTU) Press.This paper adopts a novel approach of Support Vector Machine (SVM) to forecast residential housing prices. as one type of machine learning algorithm, the proposed SVM encompasses a larger set of variables that are recognized as price-influencing and meanwhile enables recognizing the geographical pattern of housing price dynamics. The analytical framework consists of two steps. The first step is to identify the supporting vectors (SVs) to price variances using the stepwise multi-regression approach; and then it is to forecast the housing price variances by employing the SVs identified by the first step as well as other variables postulated by the hedonic price theory, where the housing prices in Taipei City are empirically examined to verify the designed framework. Results computed by nonparametric estimation confirm that the prediction power of using SVM in housing price forecasting is of high accuracy. Further studies are suggested to extract the geographical weights using kernel density estimates to reflect price responses to local quantiles of hedonic attributes."
"© 2017 by the authors.Traditional real estate appraisal methods obtain estimates of real estate by using mathematical modeling to analyze the existing sample data. However, the information of sample data sometimes cannot fully reflect the real-time quotes. For example, in a thin real estate market, the correlated sample data for estimated object is lacking, which limits the estimates of these traditional methods. In this paper, an optimal rubrics-based approach to real estate appraisal is proposed, which brings in crowdsourcing. The valuation estimate can serve as a market indication for the potential real estate buyers or sellers. It is not only based on the information of the existing sample data (just like these traditional methods), but also on the extra real-time market information from online crowdsourcing feedback, which makes the estimated result close to that of the market. The proposed method constructs the rubrics model from sample data. Based on this, the cosine similarity function is used to calculate the similarity between each rubric for selecting the optimal rubrics. The selected optimal rubrics and the estimated point are posted on a crowdsourcing platform. After comparing the information of the estimated point with the optimal rubrics on the crowdsourcing platform, those users who are connected with the estimated object complete the appraisal with their knowledge of the real estate market. The experiment results show that the average accuracy of the proposed approach is over 70%; the maximum accuracy is 90%. This supports that the proposed method can easily provide a valuable market reference for the potential real estate buyers or sellers, and is an attempt to use the human-computer interaction in the real estate appraisal field."
"© 2018 by Taylor & Francis Group, LLC.The clinical approaches to the chronic degenerative diseases that drain our resources, and compromise our well-being, have become almost exclusively symptom-focused. The common wisdom is that they are idiopathic with final outcomes to be managed rather than prevented or cured. That they are potentially reversible rarely enters any discussion between doctor and patient. Reversibility of Chronic Disease and Hypersensitivity, Volume 5: Treatment Options of Chemical Sensitivity, the final volume of this set, offers a much different perspective on chronic degenerative disease; one that disputes the idiopathic label attached to most, as well as the usual fatalistic prognosis."
"© 2017 Emerald Publishing Limited.Purpose - Building information modelling (BIM) is increasingly being adopted during construction projects. Design and construction practices are adjusting to the new system. BIM is intended to support the entire project life-cycle: the design and construction phases, and also facility management (FM). However, BIM-enabled FM remains in its infancy and has not yet reached its full potential. The purpose of this paper is to identify major aspects of BIM in order to derive a fully BIM-enabled FM process. Design/methodology/approach - In total, 207 papers were classified into main and subordinate research areas for quantitative analysis. These findings were then used to conceptualise a BIM-enabled FM framework grounded by innovation diffusion theory for adoption, and for determining the path of future research. Findings - Through an extensive literature review, the paper summarises many benefits and challenges. Major aspects of BIM are identified in order to describe a BIM-enabled FM implementation process grounded by innovation diffusion theory. The major research areas of the proposed framework include: planning and guidelines; value realisation; internal leadership and knowledge; procurement; FM; specific application areas; data capture techniques; data integration; knowledge management; and legal and policy impact. Each element is detailed and is supported by literature. Finally, gaps are highlighted for investigation in future research. Originality/value - This paper systematically classifies and evaluates the existing research, thus contributing to the achievement of the ultimate vision of BIM-enabled FM. The proposed framework informs facility managers, and the BIM-enabled FM implementation process. Further, the holistic survey identifies gaps in the body of knowledge, revealing avenues for future research."
"© Springer International Publishing AG 2017.The appraisal objectivity depends on the possibility to quickly and easily access to reliable real estate data in order to apply appropriate appraisal approaches. In order to ensure the objectivity of the real estate appraisals, in recent years Automated Valuation Methods (AVM) have been developed, integrating computerized real estate databases and programming languages. The Automated Valuation Methods proposed at international level usually recur to regression models, aimed to return appraisal equations based on reliable real estate databases. This approach is not applicable in some markets where lack of data does not allow the implementation of regression models. This paper proposes to implement a valuation automatic method in order to appraise properties located in atypical markets, structuring a procedural algorithm based on the mono-parametric approach and able to return punctual values related to the subject’s specifics and to the market peculiarities in a very limited area. The paper proposes also the application of similarity degree coefficients in order to take into account the differences between the amounts of the real estate features, leading to the possibility to use the mono-parametric approach also when lack of data would not recommend it."
"© 2017 Elsevier LtdThe existence of sunlight, air and other resources on earth must be used in an appropriate way for human welfare while still protecting the environment and its living creatures. The exploitation of sunlight and air as a substantial Renewable Energy (RE) source is an important research and development domain over past few years. The present and future overtaking in RE mainly comprises of (i) the development of novel technology for optimum production from the available natural resources (ii) environmental awareness, and (iii) the better management and distribution system. Like other domains (food, health, accommodation, safety, etc.), Artificial Intelligence (AI) could assist in achieving the future goals of the RE. Statistical and biologically inspired AI methods have been implemented in several studies to achieve common and future aims of the RE. The present study summarizes the review of reviews and the state-of-the-art research outcomes related to wind energy, solar energy, geothermal energy, hydro energy, ocean energy, bioenergy, hydrogen energy, and hybrid energy. Particularly, the role of single and hybrid AI approaches in research and development of the previously mentioned sources of RE will be comprehensively reviewed."
"© Springer International Publishing AG 2017.There has been an explosion of websites that manage classifieds in general, and real estate listings in particular. Many brokers have adapted their operation to exploit the potential of the web. Despite the importance of the real estate classifieds, there has been little work in analyzing such data. In fact, we are not aware of any work that attempted to analyze the textual data in real estate classifieds using data mining techniques. In this paper we propose a data mining process that exploits the textual data in real estate classifieds. We conduct the analysis on a large data set, which we gathered from three different property websites. We show that our process exploits the unstructured and ungrammatical textual features to significantly improve the prediction accuracy of a real estate unit price. We also illustrate how text mining combined with linear regression can be used to identify keywords that affect the price negatively or positively."
"© 2016 IEEE.Buying or selling a house is one of the important decisions in a person's life. Online listing websites like 'zillow.com', 'trulia.com', and 'realtor.com' etc. provide significant and effective assistance during the buy/sell process. However, they fail to supply one important information of a house that is, approximately how long will it take for a house to be sold after it first appears in the listing? This information is equally important for both a potential buyer and the seller. With this information the seller will have an understanding of what she can do to expedite the sale, i.e. reduce the asking price, renovate/remodel some home features, etc. On the other hand, a potential buyer will have an idea of the available time for her to react i.e.To place an offer. In this work, we propose a supervised regression (Cox regression) model inspired by survival analysis to predict the sale probability of a house given historical home sale information within an observation time window. We use real-life housing data collected from 'trulia.com' to validate the proposed prediction algorithm and show its superior performance over traditional regression methods. We also show how the sale probability of a house is influenced by the values of basic house features, such as price, size, # of bedrooms, # of bathrooms, and school quality."
NULL
"©2016 ACM.A smart power grid transforms the traditional electric grid into a user-centric, intelligent power network. The cost-saving potential of smart homes is an excellent motivating factor to involve users in smart grid operations. To that end, this survey explores the contemporary cost-saving strategies for smart grids from the users' perspective. The study shows that optimization methods are the most popular cost-saving techniques reported in the literature. These methods are used to plan scheduling and power utilization schemes of household appliances, energy storages, renewables, and other energy generation devices. The survey shows that trading energy among neighborhoods is one of the effective methods for cost optimization. It also identifies the prediction methods that are used to forecast energy price, generation, and consumption profiles, which are required to optimize energy cost in advance. The contributions of this article are threefold. First, it discusses the computational methods reported in the literature with their significance and limitations. Second, it identifies the components and their characteristics that may reduce energy cost. Finally, it proposes a unified cost optimization framework and addresses the challenges that may influence the overall residential energy cost optimization problem in smart grids."
"© 2016 IEEE.The Multiple Listing Service, commonly known as the MLS, is the singularly most important database where real estate agents and brokers list real estate properties for sale. It is common that agents include textual comments pertinent to the property. Although the information content of comments varies, it is usually expressed in good faith and in many cases is helpful in shedding light on the overall condition and the value of the property. Therefore, it seems reasonable that semantic text analysis would be useful to evaluate properties, or aspects thereof. As far as we're aware of, no methodology to effectively extract insight from the MLS textual portion exists. In this paper we demonstrate how textual descriptions may be exploited for property ranking. The proposed methodology, which combines supervised and unsupervised methods, identifies domain-specific concepts and combines their contributions to assign a score to a listing. We evaluate the proposed methods using both human evaluators and data-driven evaluation metrics on real datasets (complied from actual listings), and compare them to baseline approaches."
NULL
"© 2016 by World Scientific Publishing Co. Pte. Ltd.Predicting the market value of a residential property accurately without inspection by professional valuer could be beneficial for vary of organization and people. Building an Automated Valuation Model could be beneficial if it will be accurate adequately. This paper examined 47 machine learning models (linear and non-linear). These models are fitted on 1967 records of units from 19 suburbs of Sydney, Australia. The main aim of this paper is to compare the performance of these techniques using this data set and investigate the effect of spatial information on valuation accuracy. The results demonstrated that tree models named eXtreme Gradient Boosting Linear, eXtreme Gradient Boosting Tree and Random Forest respectively have best performance among other techniques and spatial information such drive distance and duration to CBD increase the predictive model performance significantly."
NULL
"© Springer International Publishing Switzerland 2016.In real estate appraisal, research has long been addressed to the experimentation of multi-parametric models able to reduce the margin of error of the estimate and to overcome or to limit, as far as possible, the problems and difficulties that the use of these models often involves. On the one hand, researchers are trying to overcome the essentially deductive approach that has characterized the traditional discipline, and on the other, to minimize the problems arising from a merely inductive approach. The real estate market is characterized by an inelastic supply and by properties whose complexity and differentiation often involve, also and especially on the demand side, subjective and psychological elements that could distort the results of an inductive investigation. This problem can be overcome by increasing the size of the survey sample, and by using statistical analysis. Statistical analyses, however, are often based on very strong assumptions. A multi-criteria valuation model that uses linear programming is applied to the real estate market. The model, integrated with the inductive and deductive approach, exceeds many of the assumptions of the best known statistical approaches."
"© 2015, Springer Science+Business Media Dordrecht.This paper estimates the economic benefits of different alternative policies considered for reducing the external effects caused by the utilization of landfills in solid waste management. The preferences of the local population in the surrounding areas of a landfill are evaluated utilizing a discrete choice experiment in which subjects are presented with alternative policy decisions that involve reducing the material processed through the landfill. Various models were employed in order to capture heterogeneous preferences, resulting in a mixture of normals modelling approach (MN-MNL) outperforming other alternative models of heterogeneity. The results show that the policy of moving the landfill away from the population does not provide the most benefits when compared to a policy of increasing recycling in the household. The economic benefits of the waste management policies are heterogeneous across the population surrounding the landfill and so the distance decay functions. Thus, the economic benefits for most waste management policies can increase or decrease the further away the subject lives from the landfill, depending on the preferences of his/her segment and the type of policy employed."
"© 2016 by the authors.The main objective of this paper is to present a systematic review of the VlseKriterijuska Optimizacija I Komoromisno Resenje (VIKOR) method in several application areas such as sustainability and renewable energy. This study reviewed a total of 176 papers, published in 2004 to 2015, from 83 high-ranking journals; most of which were related to Operational Research, Management Sciences, decision making, sustainability and renewable energy and were extracted from the ""Web of Science and Scopus"" databases. Papers were classified into 15 main application areas. Furthermore, papers were categorized based on the nationalities of authors, dates of publications, techniques and methods, type of studies, the names of the journals and studies purposes. Theresults of this study indicated that more papers on VIKOR technique were published in 2013 than in any other year. In addition, 13 papers were published about sustainability and renewable energy fields. Furthermore, VIKOR and fuzzy VIKOR methods, had the first rank in use. Additionally, the Journal of Expert Systems with Applications was the most significant journal in this study, with 27 publications on the topic. Finally, Taiwan had the first rank from 22 nationalities which used VIKOR technique."
"© 2015 Elsevier Ltd.Over the last two decades, water smart metering programs have been launched in a number of medium to large cities worldwide to nearly continuously monitor water consumption at the single household level. The availability of data at such very high spatial and temporal resolution advanced the ability in characterizing, modeling, and, ultimately, designing user-oriented residential water demand management strategies. Research to date has been focusing on one or more of these aspects but with limited integration between the specialized methodologies developed so far. This manuscript is the first comprehensive review of the literature in this quickly evolving water research domain. The paper contributes a general framework for the classification of residential water demand modeling studies, which allows revising consolidated approaches, describing emerging trends, and identifying potential future developments. In particular, the future challenges posed by growing population demands, constrained sources of water supply and climate change impacts are expected to require more and more integrated procedures for effectively supporting residential water demand modeling and management in several countries across the world."
"© 2015 The Author(s). Published by Taylor & Francis.Multiple criteria decision-making (MCDM) is considered as a complex decision-making (DM) tool involving both quantitative and qualitative factors. In recent years, several MCDM techniques and approaches have been suggested to choosing the optimal probable options. The purpose of this article is to systematically review the applications and methodologies of the MCDM techniques and approaches. This study reviewed a total of 393 articles published from 2000 to 2014 in more than 120 peer reviewed journals (extracted from Web of Science). According to experts’ opinion, these articles were grouped into 15 fields. Furthermore, these articles were categorised based on authors, publication date, name of journals, methods, tools, and type of research (MCDM utilising research, MCDM developing research, and MCDM proposing research). The results of this study indicated that in 2013 scholars have published articles more than in other years. In addition, the analytic hierarchy process (AHP) method in the individual tools and hybrid MCDM in the integrated methods were ranked as the first and second methods in use. Additionally, the European Journal of Operational Research as the first journal with 70 publications was the significant journal in this study. Finally, energy, environment and sustainability were ranked as the first areas that have applied MCDM techniques and approaches."
"© 2015 ACM.Mixed land use refers to the effort of putting residential, commercial and recreational uses in close proximity to one another. This can contribute economic benefits, support viable public transit, and enhance the perceived security of an area. It is naturally promising to investigate how to rank real estate from the viewpoint of diverse mixed land use, which can be reflected by the portfolio of community functions in the observed area. To that end, in this paper, we develop a geographical function ranking method, named FuncDivRank, by incorporating the functional diversity of communities into real estate appraisal. Specifically, we first design a geographic function learning model to jointly capture the correlations among estate neighborhoods, urban functions, temporal effects, and user mobility patterns. In this way we can learn latent community functions and the corresponding portfolios of estates from human mobility data and Point of Interest (POI) data. Then, we learn the estate ranking indicator by simultaneously maximizing ranking consistency and functional diversity, in a unified probabilistic optimization framework. Finally, we conduct a comprehensive evaluation with real-world data. The experimental results demonstrate the enhanced performance of the proposed method for real estate appraisal."
"© 2015 Elsevier Ltd.Periodic monitoring and multi-scale characterization of urban sprawl is essential for improving urban planning and development. However, historical sprawl analysis is not well suited for the neo-urbanization occurring in most cities in China due to the limited data available. This paper proposes a concise and cost-effective method for automating the extraction of urban boundaries (UBs). The method uses integrated land-use information entropy (LUIE) model along with ordinary Kriging based on a gridded land-use map derived from Landsat imagery to extract UBs. Results indicate that overall extraction accuracies greater than 90% were obtained using an 800m-resolution LUIE combined with Kriging. The method was applied to identify UBs in Wuhan, China during 1987-2010, and the UBs were characterized at multiple scales and analyzed using landscape metrics. Results show varied landscape dynamics at local administrative and city scales. The study demonstrates that the method for UB identification and multi-scale analysis has the potential to contribute to sprawl monitoring and measurement at multiple spatial scales. Moreover, the findings from this study can potentially guide policy makers and urban planners tasked with understanding and controlling development occurring under neo-urbanization strategies in China."
"© 2015 by John Wiley & Sons, Inc. All rights reserved.Survey's the issues typically raised in discussions of sustainability and plastics Discusses current issues not covered in detail previously such as ocean litter, migration of additives into food products and the recovery of plastics Covers post-consumer fate of plastics on land and in the oceans, highlighting the environmental impacts of disposal methods Details toxicity of plastics, particularly as it applies to human health Presents a clear analysis of the key plastic-related issues including numerous citations of the research base that supports and contradicts the popularly held notions."
"© 2016 by Taylor and Francis Group, LLC.When confronted with a problem in science, the way to proceed is not always obvious. The problem may seem intractable or there may be many possible solutions, with some better than others. Problem-Solving Exercises in Green and Sustainable Chemistry teaches students how to analyze and solve real-world problems that occur in an environmental context, and it encourages creativity in developing solutions to situations based on events that have actually taken place. The problems described in this book are relevant and stimulating in learning and understanding the principles of green and sustainable chemistry. They address various aspects of the field, including: Toxicity Waste generation and disposal Chemical accidents Energy efficiency New policy development The final chapter contains proposed solutions to the presented problems and provides commentaries and references to relevant literature. This book also prompts students to become more comfortable with the idea of multiple “correct” answers to problems. It emphasizes the reality that green chemistry is about making practical decisions and weighing multiple factors that are often conflicting, thus making it difficult or impossible to apply one perfect solution to a given situation. Problem-Solving Exercises in Green and Sustainable Chemistry prepares students to solve challenging problems, whether as green chemists, as architects designing energy-efficient buildings, or as environmentally-conscious citizens."
© Springer International Publishing Switzerland 2015.A method for enhancing property valuation models consists in determining zones of an urban municipality in which the prices of residential premises change similarly over time. Such similar zones are then merged into bigger areas embracing greater number of sales transactions which constitute a more reliable basis to construct accurate property valuation models. This is especially important when machine learning algorithms are employed do create prediction models. In this paper we present our further investigation of the method using the cadastral regions of a city as zones for merging. A series of evaluation experiments was conducted using real-world data comprising the records of sales and purchase transactions of residential premises accomplished in a Polish urban municipality. Six machine learning algorithms available in the WEKA data mining system were employed to generate property valuation models. The study showed that the prediction models created over the merged cadastral regions outperformed in terms of accuracy the models based on initial component regions.
NULL
"The present-day regional environmental control widely uses automation equipment. Nonetheless, no cardinal improvement of ecological situation is observed in the areas under automated monitoring with state-of-the-art equipment and advanced geoinformation aerospace technologies (e.g., International Air Quality, Black Triangle). This is in many ways related with the fact that these systems, though efficient in data capture and adequate valuation of current status of natural environment, offer a very feeble analytical support in decision-making on control actions. Mainly, such a system is to maintain databases and transfer eco-data to parties concerned. Improvement of automated systems only deals with techniques: expansion of stations, engineering and introduction of advanced facilities and metrological provision, development of remote control and observation methods. However, current biotechnosphere dynamics forecasting, situation modeling and development of potential control scenarios are in a state of neglect. This extremely complicates conversion of the acquired eco-information in immediate managerial decisions on prevention and mitigation of ecological risk, as well as on using the eco-data in strategic planning of industrial development in a region based on compatibility with biosphere. The authors put forward a version of automated environmental control system for mining-and-metallurgy cluster based on integration of three intelligent subsystems: ecomonitoring, managerial decision-making support and control. The study was conducted under government order in the field of scientific work under project No. 671 ""Development of Intelligent Technology for Monitoring and Forecasting of Induced Ecological Risks, and for Regional Technosphere Safety Control"" (customer-RF Ministry of Education and Science)."
NULL
"© 2014 WIT Press.Over the last decade, a consistent increase in real-estate prices, both in Italy and others OECD member countries, has been registered. This rise in price and the following subprime mortgage scandal have resulted in a significant fluctuation in market prices and/or market activity and in a consequent spreading of concerns about future market trends. These factors and the actual economic crisis often preclude people from buying residential properties, especially for those who want to set up house for the first time. Considering the limited public purchasing power and the unemployment increase, social housing and other related public policies must be assisted by appropriate decision support systems in order to provide affordable housing solutions to local citizens in financial need. These systems need to be able to identify in which nationwide contexts it is necessary to act with more incisive determination. Such a need also has to be considered in terms of support for the local population in order to get a better awareness of real estate acquisition risks. This work aims to analyse the general affordability level of residential properties in urban environments, through a spatial decision support system (SDSS). At present, the system is still in the development phase, but is able to generate a qualitative overview of the housing market supply, especially in those contexts where the acquired dataset is characterized by a suitable spatial density. Using this information, it is possible to assess the income level required to affordably meet the current housing market supply and compare it to the official average income registered within the area of study."
"© 2014 IEEE.Ranking residential real estates based on investment values can provide decision making support for home buyers and thus plays an important role in estate marketplace. In this paper, we aim to develop methods for ranking estates based on investment values by mining users' opinions about estates from online user reviews and offline moving behaviors (e.g., Taxi traces, smart card transactions, check-ins). While a variety of features could be extracted from these data, these features are Interco related and redundant. Thus, selecting good features and integrating the feature selection into the fitting of a ranking model are essential. To this end, in this paper, we first strategically mine the fine-grained discrminative features from user reviews and moving behaviors, and then propose a probabilistic sparse pair wise ranking method for estates. Specifically, we first extract the explicit features from online user reviews which express users' opinions about point of interests (POIs) near an estate. We also mine the implicit features from offline moving behaviors from multiple perspectives (e.g., Direction, volume, velocity, heterogeneity, topic, popularity, etc.). Then we learn an estate ranking predictor by combining a pair wise ranking objective and a sparsity regularization in a unified probabilistic framework. And we develop an effective solution for the optimization problem. Finally, we conduct a comprehensive performance evaluation with real world estate related data, and the experimental results demonstrate the competitive performance of both features and the proposed model."
"Drawing useful predictions from vast accumulations of data is becoming critical to the success of an enterprise. Organizations' databases grow exponentially from transactions with external stakeholders in addition to their own internal activities. An important organizational computing issue is that, as they grow, the databases become potentially more valuable and also more difficult to analyze. One example is predicting the value of residential real estate based on past comparable sales transactions. This is critical to several important sectors of the US economy including the mortgage finance industry and local governments that collect property taxes. The common methodology for dealing with such property valuation is based on multiple regression, although this methodology has been found to be deficient. Data mining methods have been proposed and tested as an alternative, but the results are very mixed. This article introduces a novel approach for improving predictions using an adaptive, neuro-fuzzy inference model, and illustrates its application to real estate property price prediction through the use of comparable properties. Although neuro-fuzzy-based approaches have been found to be effective for classification and estimation in many fields, there is very little existing work that investigates their potential in a real estate context. In addition, this article addresses several common problems in existing studies, such as small sample size, lack of rigorous data sampling, and poor model validation and testing. Our model is tested with real sales data from the assessment office in a large US city. The results show that the neuro-fuzzy model is superior in all of the test scenarios. The article also discusses and refines a unique technique to defining comparable properties to improve accuracy. Test results show very promising potential for this technique in mass appraisal in real estate and similar contexts when used with the neuro-fuzzy model. © 2014 Copyright Taylor and Francis Group, LLC."
"We urgently need to transform to a low carbon society, yet our progress is painfully slow, in part because there is widespread public concern that this will require sacrifice and high costs. But this need not be the case. Many carbon reduction policies provide a range of additional benefits, from reduced air pollution and increased energy security to financial savings and healthier lifestyles, that can offset the costs of climate action. This book maps out the links between low carbon policies and their co-benefits, and shows how low carbon policies can lead to cleaner air and water, conservation of forests, more sustainable agriculture, less waste, safer and more secure energy, cost savings for households and businesses and a stronger and more stable economy. The book discusses the ways in which joined-up policies can help to maximise the synergies and minimise the conflicts between climate policy and other aspects of sustainability. Through rigorous analysis of the facts, the author presents well-reasoned and evidenced recommendations for policy-makers and all those with an interest in making a healthier and happier society. This book shows us how, instead of being paralysed by the threat of climate change, we can use it as a stimulus to escape from our dependence on polluting fossil fuels, and make the transition to a cleaner, safer and more sustainable future. © 2013 Alison Smith. All rights reserved."
"An approach to apply ensembles of regression models, built over the chunks of a data stream, to aid in residential premises valuation was proposed. The approach consists in incremental expanding an ensemble by systematically generated models in the course of time. The output of aged component models produced for current data is updated according to a trend function reflecting the changes of premises prices since the moment of individual model generation. The method employing general linear model, multiple layer perceptron, and radial basis function networks was empirically compared with evolving fuzzy systems designed for incremental learning from data streams.The results showed thatevolving fuzzy systems and general linear models outperformed the ensembles built using artificial neural networks. © Springer-Verlag 2013."
"© 2014 by IGI Global. All rights reserved.As geospatial visualizations grow in popularity, their role in human activities is also evolving. While maps have been used to support higher-level cognitive activities such as decision-making, sense making, and knowledge discovery, traditionally their use in such activities has been partial. Nowadays they are being used at various stages of such activities. This trend is simultaneously being accompanied with another shift: a movement from the design and use of data-centered geospatial visualizations to activity-centered visualizations. Data-centered visualizations are primarily focused on representation of data from data layers; activity-centered visualizations, not only represent the data layers, but also focus on users' needs and real-world activities-such as storytelling and comparing data layers with other information. Examples of this shift are being seen in some mashup techniques that deviate from standard data-driven visualization designs. Beyond the discussion of the needed shift, this chapter presents ideas for designing human-activity-centered geospatial visualizations."
"Purpose – The housing sector is one of the main sources of economic growth in both developing and developed countries. Although many methods for modeling house prices have been proposed, each has its own limitations. The present paper aims to propose gene expression programming (GEP) as a new approach for prediction of housing price. Design/methodology/approach – This study introduces gene expression programming (GEP) as a new approach for predicting housing price. This is the first time that this metaheuristic method is used in the housing literature. Findings – The housing price model based on the gene expression programming is compared with a least square regression model that is derived from a stepwise process. The results indicate that the GEP-based model provides superior performance to the traditional regression. Originality/value – Data used in this study is derived from the Household Income and Expenditure Survey (HIES) in Iran that is conducted by the Statistical Center of Iran (SCI). Housing price model is estimated by administering the questionnaires of this survey in Hamedan Province. To show the applicability of the derived model by GEP technique, it is verified applying parts of the data, namely test data sets that were not included in the modeling process. © 2013, Emerald Group Publishing Limited"
NULL
"Characterizing the spatial distribution of urban land price is essential for improving urban planning and management, as well as for effectively modeling and predicting changes in urban land use. Previous studies have shown that in using conventional geostatistics methods to characterize the local structure of land price, there is controversy regarding the effectiveness of interpolation. In this paper, a recently developed Multifractal Inverse Distance Weighted (MIDW) interpolation method is applied to characterize the spatial structure of land price, and a spectrum analysis method (S- A) based on a fractal filtering technique is applied to separate the singularity from the background of land price distribution; these methods are applied to a study site in the city of Wuhan (China). It is shown that the MIDW interpolation method is a valid and effective alternative for characterizing land price distribution by comparison with ordinary IDW and Kriging methods. Based on deviation and parameters, the results of the MIDW method not only fit better with the surveyed values, but they also incorporate both the singularity and spatial association in data interpolation. The singularity of land price, which could be attributed to local special landscapes, such as the Yangtze River and East Lake, was successfully separated from its background by the S- A method. The background, which represents the overall spatial trend of land price distribution, was reclassified by the fractal concentration-area method. The derived singularity and background will better aid the decision-making process for urban planning. © 2012."
NULL
"Quick and accurate adapting selling can boost business results. This study developed an adapting selling solution by combining case-based reasoning (CBR) and rough set theory for industrial proposal generation in business-to-business (B2B) context. In this regard, CBR was developed to find the right proposal by considering users' needs. Rough set theory is then developed to find the proper attribute weights for CBR retrieval phase. Further, when cases have same problem features or they have same similarity values, it is not possible to select one case among the retrieved cases. For this purpose, this study presented a new method to discriminate equally retrieved cases. Sales data of a steel manufacturing company are used and inputted into the CBR system. Practical application of the proposed system illustrated efficacy of the procedures and algorithms. Copyright © 2013 Inderscience Enterprises Ltd."
"Environmental informatics has experienced extraordinarily rapid progress in the past decade and has made an invaluable contribution to planning, design, and operations for waste management. In many cases, however, the roles of these information technologies have been limited to stand-alone projects without synergistic effects. This article presents a holistic view and an in-depth discussion of environmental informatics applied to solid and hazardous waste management from the onset to the present status, and to future trends aiming to advance the management potential. With regard to building, maintaining, and developing knowledge-based or artificial intelligence systems, the spectrum of environmental informatics for solid and hazardous waste management can be classified into five categories: database system, geographical information system, decision support system, expert system, and integrated environmental information system. Supporting technologies in the integrated environmental information system can be further divided into five classes in a logical order to enhance understanding: data acquisition, data communication, data and knowledge storage, data mining and knowledge discovery, and data and knowledge utilization. This critical review article may help create sustainable development strategies from a local solution to global opportunities that will elevate environmental informatics to a new level in dealing with more complex problems and large-scale applications for integrated solid and hazardous waste management. © 2013 Copyright Taylor and Francis Group, LLC."
"The vastly increasing number of online hotel room bookings is not only intensifying the competition in the travel industry as a whole, but also prompts travel intermediates (i.e. e-companies that aggregate information about different travel products from different travel suppliers) into a fierce competition for the best prices of travel products, i.e. hotel rooms. An important factor that affects revenues is the ability to conclude profitable deals with different travel suppliers. However, the profitability of a contract not only depends on the communication skills of a contract manager. It significantly depends on the objective information obtained about a specific travel supplier and his/her products. While the contract manager usually has a broad knowledge of the travel business in general, collecting and processing specific information about travel suppliers is usually a time and cost expensive task. Our goal is to develop a tool that assists the travel intermediate to acquire the missing strategic information about individual hotels in order to leverage profitable deals. We present a GIS-based decision support system that can both, estimate objective hotel room rates using essential hotel and locational characteristics and predict temporal room rate prices. Information about objective hotel room rates allows for an objective comparison and provides the basis for a realistic computation of the contract's profitability. The temporal prediction of room rates can be used for monitoring past hotel room rates and for adjusting the price of the future contract. This paper makes three major contributions. First, we present a GIS-based decision support system, the first of its kind, for hotel brokers. Second, the DSS can be applied to virtually any part of the world, which makes it a very attractive business tool in real-life situations. Third, it integrates a widely used data mining framework that provides access to dozens of ready to run algorithms to be used by a domain expert and it offers the possibility of adding new algorithms once they are developed. The system has been designed and evaluated in close cooperation with a company that develops travel technology solutions, in particular inventory management and pricing solutions for many well-known websites and travel agencies around the world. This company has also provided us with real, large datasets to evaluate the system. We demonstrate the functionality of the DSS using the hotel data in the area of Barcelona, Spain. The results indicate the potential usefulness of the proposed system. © 2012 Elsevier B.V."
"© 2012 Elsevier Inc. All rights reserved.Safety in the process industries is critical for those who work with chemicals and hazardous substances or processes. The field of loss prevention is, and continues to be, of supreme importance to countless companies, municipalities and governments around the world, and Lees' is a detailed reference to defending against hazards. Recognized as the standard work for chemical and process engineering safety professionals, it provides the most complete collection of information on the theory, practice, design elements, equipment, regulations and laws covering the field of process safety. An entire library of alternative books (and cross-referencing systems) would be needed to replace or improve upon it, but everything of importance to safety professionals, engineers and managers can be found in this all-encompassing three volume reference instead. THE process safety encyclopedia, trusted worldwide for over 30 years. Now available in print and online, to aid searchability and portability. Over 3,600 print pages cover the full scope of process safety and loss prevention, compiling theory, practice, standards, legislation, case studies and lessons learned in one resource as opposed to multiple sources."
"The purpose of this paper is to review the literature on the applications of the Analytic Hierarchy Process (AHP) in operations management and suggest possible gaps from the point of view of researchers and practitioners. This paper systematically categorises the published literature from 1990 to 2009 in 291 peer reviewed journals articles (searched via Emerald, Ingenta, MetaPress, ProQuest, and ScienceDirect) and then reviews and analyses them methodologically. Our analysis has revealed that a significant number of AHP applications are found when problems require considerations of both quantitative and qualitative factors (e.g.; socioeconomic operations decisions). AHP has been largely applied to macro (complex and real) and people (managerial- subjective) oriented problems. The most addressed decision themes are product and process design and, managing the supply chain. A majority of AHP applications are application or case study oriented and only a few papers aimed at contributing to AHP modelling before applying to practical problems. Our review has found that significant research gap exists in the application of AHP in the areas of forecasting, layout of facilities and managing stocks. This paper presents a comprehensive listing of AHP applications in operations management and develops a framework for identifying the decision areas that have better research gaps to be studied by future researchers. © 2012 Elsevier B.V. All rights reserved."
"In this paper, we investigate fuzzy modeling techniques for predicting the prices of residential premises, based on some main drivers such as usable area of premises, age of a building, number of rooms in a flat, floor on which a flat is located, number of storeys in a building as well as the distance from the city center. Our proposed modeling techniques rely on two aspects: the first one (called SparseFIS) is a batch off-line modeling method and tries to out-sparse an initial dense rule population by optimizing the rule weights within an iterative optimization procedure subject to constrain the number of important rules; the second one (called FLEXFIS) is a single-pass incremental method which is able to build up fuzzy models in an on-line sample-wise learning context. As such, it is able to adapt former generated prediction models with new data recordings on demand and also to cope with on-line data streams. The final obtained fuzzy models provide some interpretable insight into the relations between the various features and residential prices in form of linguistically readable rules (IF-THEN conditions). Both methods will be compared with a state-of-the-art premise estimation method usually conducted by many experts and exploiting heuristic concepts such as sliding time window, nearest neighbors and averaging. The comparison is based on a two real-world data set including prices for residential premises within the years 1998-2008. © 2011 Elsevier Inc. All rights reserved."
NULL
"Computational and digital advancements with the advent of relationship marketing have changed the land signs of business. Digital revolution led to generation and collection of data in companies and extracting knowledge from this data through knowledge discovery in databases (KDD) process. KDD involves many steps, of which an important step is data mining. Data mining is a process of extracting patterns in data through statistical and other techniques and algorithms. In business, firms are shifting their marketing approach from mass marketing to relationship based marketing leading to an era of customer relationship management (CRM). CRM requires sustainable long term relationship with customers and allocation of resources to maintain these relationships. Customer lifetime value (CLV) is a metric to justify resource allocation by segregating customers on the basis of their contribution to the company. In this paper we review applications of statistical and data mining techniques for predicting CLV and its parameters. The applications of techniques such as logistic regression, decision trees, artificial neural networks, genetic algorithms, fuzzy logic and support vector machines are covered. In the end, a case study is presented to estimate few CLV parameters for a direct marketing company. © 2010 Inderscience Enterprises Ltd."
"The experiments aimed to compare machine learning algorithms to create models for the valuation of residential premises were conducted using the SAS Enterprise Miner 5.3. Eight different algorithms were used including artificial neural networks, statistical regression and decision trees. All models were applied to actual data sets derived from the cadastral system and the registry of real estate transactions. A dozen of predictive accuracy measures were employed. The results proved the usefulness of majority of algorithms to build the real estate valuation models. © 2009 Springer-Verlag Berlin Heidelberg."
The experiments aimed to compare data driven soft computing models for the valuation of residential premises were conducted using the KEEL tool (Knowledge Extraction based on Evolutionary Learning). Twelve regression algorithms were applied to actual data sets derived from the cadastral system and the registry of real estate transactions. The 5×2-fold cross validation and nonparametric statistical tests were applied. The results proved the usefulness of the tool to carry out laborious investigation in a relatively short time. Further research is needed to determine to what extent data coming from such sources allow to build the real estate valuation models. © 2009 IEEE.
NULL
"© Stuart N. Soroka 2014. All rights reserved.This book explores the political implications of the human tendency to prioritize negative information over positive information. Drawing on literatures in political science, psychology, economics, communications, biology, and physiology, this book argues that “negativity biases” should be evident across a wide range of political behaviors. These biases are then demonstrated through a diverse and cross-disciplinary set of analyses, for instance: in citizens' ratings of presidents and prime ministers; in aggregate-level reactions to economic news, across 17 countries; in the relationship between covers and newsmagazine sales; and in individuals' physiological reactions to network news content. The pervasiveness of negativity biases extends, this book suggests, to the functioning of political institutions - institutions that have been designed to prioritize negative information in the same way as the human brain."
"The experiments aimed to compare machine learning algorithms to create models for the valuation of residential premises, implemented in popular data mining systems KEEL, RapidMiner and WEKA, were carried out. Six common methods comprising two neural network algorithms, two decision trees for regression, and linear regression and support vector machine were applied to actual data sets derived from the cadastral system and the registry of real estate transactions. A dozen of commonly used performance measures was applied to evaluate models built by respective algorithms. Some differences between models were observed. © 2009 Springer Berlin Heidelberg."
"The experiments aimed to compare evolutionary fuzzy algorithms to create models for the valuation of residential premises were conducted using KEEL. Out of 20 algorithms divided into 5 groups to final comparison five best were selected. All models were applied to actual data sets derived from the cadastral system and the registry of real estate transactions. A dozen of predictive accuracy measures were employed. Although statistical tests were not decisive, final evaluation of models could be done on the basis of the measures used. © 2009 Springer Berlin Heidelberg."
"A series of experiments aimed to generate and learn fuzzy models for the valuation of residential premises was conducted using the KEEL tool (Knowledge Extraction based on Evolutionary Learning). Four regression and four post-processing algorithms were applied to several data sets. They referred to sales/purchase transactions of residential premises, which were derived from the cadastral system and the registry of real estate transactions. The results proved the usefulness of the tool to carry out laborious and tedious investigation in a relatively short time. Further research is needed to determine to what extent data coming from such sources allow to build the real estate valuation models. © 2008 IEEE."
"Fuzzy models to assist with real estate appraisals are described and previous experiments on optimizing them with evolutionary algorithms implemented in MATLAB are summarized. An approach was made to use the KEEL Tool, developed in Java by a group of Spanish research centres, to investigate the models. Five fuzzy models comprising 3 or 4 input variables referring to the attributes of a property were learned and evaluated using six regression algorithms for fuzzy rule based systems implemented in the KEEL Tool. The experiments were conducted using a data set prepared on the basis of actual 134 sales transactions made in one of Polish cities and located in a residential section. The results were encouraging. The KEEL Tool has proved to be very useful and effective research tool, especially thanks to its 10-fold cross validation mechanism and relatively short time of data processing. © 2008 The authors and IOS Press. All rights reserved."
NULL
"© Intergovernmental Panel on Climate Change 2007.The Climate Change 2007 volumes of the Fourth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC) provide the most comprehensive and balanced assessment of climate change available. This IPCC Working Group III volume is a state-of-the-art assessment of the scientific, technical, environmental, economic, and social aspects of the mitigation of climate change. Written by the world's leading experts, the IPCC volumes will again prove to be invaluable for researchers, students, and policymakers, and will form the standard reference works for policy decisions for government and industry worldwide."
"Many countries now actively encourage land use change for the provision of multiple benefits, specifically including non-market benefits. Often such policies have been poorly designed because of a lack of understanding of the spatial distribution of the potential costs and-especially-non-market benefits from land use change. As with market goods, the potential yield of non-market goods and services from land use can be highly spatially variable. In recent years, more and more studies on the economic aspects of natural resources have started to make use of Geographical Information Systems (GIS). What is yet lacking is the systematic adoption of a framework for the spatial targeting of policy interventions which can be used to improve decision making in terms of effectiveness, efficiency, equity or public acceptability. This paper uses existing studies in forestry to present such a framework and discusses its potential uses and limitations as a new standard tool to inform multi-functional land use decisions. © 2005 Elsevier B.V. All rights reserved."
"Purpose - The traditional models of real estate market have several sources of imprecision, such as transitions between submarkets, generating difficulties in property valuation. The purpose of this paper is to examine an alternative to improve mass appraisal models, using fuzzy rules. Design/methodology/approach - Fuzzy rule-based systems (FRBS) are able to generate flexible systems and may be useful in considering vagueness or imprecision presents in real estate market. An application to the housing market of Porto Alegre (Brazil), with more than 30,000 apartments, transacted in 1998-2001, illustrates the fuzzy system, comparing with traditional hedonic regression model. Findings - The results have indicated the potential of fuzzy rules to use in mass appraisal. Originality/value - This paper presents a procedure to develop mass appraisal models using FRBS. © Emerald Group Publishing Limited."
"Residential neighborhoods are defined as convex geographical areas containing similar populations and roughly homogeneous housing markets. Neighborhoods are relevant largely because confidentiality requires spatial aggregation of data collected at the household level. A hedonic model using individual sales transactions and their street addresses is combined with CART (Classification and Regression Trees) to define the optimal number of neighborhoods and to place neighborhood boundaries in one Connecticut town. There are about half the number of CART neighborhoods than there are census tracts. Moreover, the CART boundaries typically run behind the houses rather than down the middle of the street, and they reduce residual variation. The CART model is important to the submarkets literature, which aggregates neighborhoods into larger homogeneous markets. Moreover, anisotropic spatial autocorrelation can be modeled with CART neighborhoods. © 2005 Elsevier Inc. All rights reserved."
"Purpose Available literature claims that location is a key attribute in the housing market. However, the impact of this attribute is difficult to measure and the traditional hedonic approach using subjective assessments is problematic. This paper seeks to explore trend surface analysis technique, attempting to provide an alternative way to measure location values. Design/methodology/approach TSA works in a similar way to other response surface methods but it is implemented directly in regression models, using a set of combinations of the co-ordinates of properties in several power degrees. It can also be implemented in artificial neural networks, taking advantage of the neural ability in non-linear domains. This work presents a comparison between traditional regression approach, error modelling, response surfaces, and TSA. ANN is also used to estimate some models, comparing their results. The objective is to verify the behaviour of TSA in hedonic models. A case study was carried using data of over 30,000 sales tax data of apartments sold in Porto Alegre, a southern Brazilian town. Findings The results indicates that TSA is an effective tool for the spatial analysis of real estate, because TSA models are similar to other approaches, but are developed with less expert work. Originality/value This paper presents an application of TSA in real estate market, which is an interesting alternative to traditional measures of location attributes. © 2005, Emerald Group Publishing Limited"
"In recent years, engineering geology has been trying to redefine itself in terms of a set of 'core values' or 'special scientific principles.' John Knill (2003) illustrated the essence of engineering geology in the engineering geological triangle. One way of trying to understand the relationships between some of the 'core values' is through the engineering geological ground model, which seeks to combine understanding of the spatial distribution of engineering boundaries with knowledge of rock and soil material, and mass, properties and the geological processes that alter these through time. The rapid development in information technology over the last twenty years and the digitization of increasing amounts of geological data has brought engineering geology to a situation in which the production of meaningful 3D spatial models of the shallow subsurface is feasible. The paper describes how this can be done and points the way to the next stage that involves the attribution of these spatial models with physical, mechanical and chemical property data. Some new developments in the provision of geohazard susceptibility information at the national scale are also discussed. A future is proposed in which site investigation sets out to test a pre-existing spatial model based on real data, rather than trying to create such a model based on concepts alone. © 2005 Geological Society of London."
NULL
"This paper presents a literature review of quality function deployment (QFD) based on a reference bank of about 650 QFD publications established through searching various sources. The origination and historical development of QFD, especially in Japan and the US, are briefly accounted first, followed by a partial list of QFD organizations, softwares, and online resources. Then a categorical analysis is conducted about QFD's functional fields, applied industries and methodological development. Ten informative QFD publications are also suggested, particularly for those who are not yet familiar with QFD. It is hoped that the paper can serve the needs of researchers and practitioners for easy references of QFD studies and applications, and hence promote QFD's future development. © 2002 Elsevier Science B.V. All rights reserved."
"This article is motivated by the limited ability of standard hedonic price equations to deal with spatial variation in house prices. Spatial patterns of house prices can be viewed as the sum of many causal factors: Access to the central business district is associated with a house price gradient; access to decentralized employment subcenters causes more localized changes in house prices; in addition, neighborhood amenities (and disamenities) can cause house prices to change rapidly over relatively short distances. Spatial prediction (e.g., for an automated valuation system) requires models that can deal with all of these sources of spatial variation. We propose to accommodate these factors using a standard hedonic framework but incoporating a semiparametric model with structure in the residuals modeled with a partially Bayesian approach. The Bayesian framework enables us to provide complete inference in the form of a posterior distribution for each model parameter. Our model allows prediction at sampled or unsampled locations as well as prediction interval estimates. The nonparametric part of our model allows sufficient flexibility to find substantial spatial variation in house values. The parameters of the kriging model provide further insights into spatial patterns. Out-of-sample mean squared error and related statistics validate the proposed methods and justify their use for spatial prediction of house values."
